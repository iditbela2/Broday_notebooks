{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (1)- data imputation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upload matlab's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annots = loadmat('cars_train_annos.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check verious methods for data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/facing-the-arima-model-against-neural-networks-745ba5a933ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally, I tried to write a script that extracts all PM2.5 data available from environmental protection of Israel. But then I used Yuval's data from matlab (above). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arima models Vs. ML:\n",
    "# https://towardsdatascience.com/facing-the-arima-model-against-neural-networks-745ba5a933ca\n",
    "\n",
    "# time-series analysis in plurasight:\n",
    "\n",
    "# FA and PCA in plurasight:\n",
    "# https://app.pluralsight.com/course-player?clipId=9306a799-e3f5-41bc-bb65-474dafec524d\n",
    "    \n",
    "# FA in python:\n",
    "# https://www.datacamp.com/community/tutorials/introduction-factor-analysis\n",
    "# from factor_analyzer import FactorAnalyzer\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FactorAnalysis.html#sklearn.decomposition.FactorAnalysis\n",
    "# blind source seperation? if non-Gaussian priors on the latent variables are assumed.\n",
    "# https://scikit-learn.org/stable/auto_examples/decomposition/plot_ica_blind_source_separation.html#sphx-glr-auto-examples-decomposition-plot-ica-blind-source-separation-py\n",
    "# https://scikit-learn.org/stable/modules/decomposition.html\n",
    "\n",
    "# technically when we say FA we mean varimax-rotated principal component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.random.rand(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.random.rand(10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = np.random.rand(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39887499, 0.25868312, 0.79348595],\n",
       "       [0.5840844 , 0.87063411, 0.84165557],\n",
       "       [0.16245394, 0.35716553, 0.28596862],\n",
       "       [0.74534349, 0.22252331, 0.75446334],\n",
       "       [0.65277712, 0.96770442, 0.30318783],\n",
       "       [0.11232998, 0.41472656, 0.91533984],\n",
       "       [0.74274971, 0.86629095, 0.44709888],\n",
       "       [0.61750942, 0.64176317, 0.48511266],\n",
       "       [0.7446682 , 0.50462566, 0.17565843],\n",
       "       [0.22539797, 0.72084979, 0.73391664]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.95959013, 0.22197795, 0.39603034, 0.95842235, 0.04710638],\n",
       "       [0.28557944, 0.2614658 , 0.36862438, 0.17232797, 0.93638644],\n",
       "       [0.18525169, 0.50439401, 0.00849516, 0.39499191, 0.72722094]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6036257 , 0.5564078 , 0.26006429, 0.74028957, 0.83805652],\n",
       "       [0.96503495, 0.78182093, 0.5594021 , 1.04228129, 1.45483363],\n",
       "       [0.3108645 , 0.27368862, 0.19842596, 0.33020439, 0.55005994],\n",
       "       [0.91853795, 0.60417885, 0.38361544, 1.05070776, 0.79213978],\n",
       "       [0.95892103, 0.55084986, 0.61781462, 0.91215546, 1.15737979],\n",
       "       [0.39579637, 0.59506353, 0.20514036, 0.54068038, 1.05929008],\n",
       "       [1.042956  , 0.61689351, 0.61728556, 1.03775452, 1.17131101],\n",
       "       [0.86569825, 0.54956051, 0.48524313, 0.89404414, 0.98281104],\n",
       "       [0.89122799, 0.38584333, 0.48242077, 0.87005142, 0.63534574],\n",
       "       [0.55810885, 0.6086941 , 0.36122198, 0.63014016, 1.21933119]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.matmul(G,F)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(G[:,2],(-1,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(F[2,:],(1,-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38275651, 0.08854145, 0.1579666 , 0.38229071, 0.01878956],\n",
       "       [0.56048163, 0.12965386, 0.23131514, 0.55979955, 0.0275141 ],\n",
       "       [0.1558892 , 0.03606119, 0.06433669, 0.15569949, 0.00765262],\n",
       "       [0.71522426, 0.16544982, 0.29517863, 0.71435386, 0.03511043],\n",
       "       [0.62639848, 0.14490213, 0.25851954, 0.62563619, 0.03074997],\n",
       "       [0.10779074, 0.02493478, 0.04448608, 0.10765956, 0.00529146],\n",
       "       [0.71273529, 0.16487406, 0.29415142, 0.71186792, 0.03498825],\n",
       "       [0.59255594, 0.13707347, 0.24455246, 0.59183483, 0.02908863],\n",
       "       [0.71457626, 0.16529992, 0.2949112 , 0.71370665, 0.03507862],\n",
       "       [0.21628967, 0.05003338, 0.08926443, 0.21602645, 0.01061768]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# G1*F1 \n",
    "# X matrix related to factor1\n",
    "np.matmul(np.reshape(G[:,0],(-1,1)),np.reshape(F[0,:],(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07387458, 0.06763679, 0.09535691, 0.04457834, 0.24222737],\n",
       "       [0.2486352 , 0.22764104, 0.32093696, 0.1500346 , 0.81524997],\n",
       "       [0.10199913, 0.09338657, 0.13165992, 0.06154961, 0.33444496],\n",
       "       [0.06354808, 0.05818224, 0.08202752, 0.03834699, 0.20836781],\n",
       "       [0.27635649, 0.25302161, 0.35671944, 0.16676253, 0.90614529],\n",
       "       [0.11843738, 0.10843681, 0.15287832, 0.07146898, 0.38834433],\n",
       "       [0.24739488, 0.22650546, 0.31933597, 0.14928616, 0.8111831 ],\n",
       "       [0.18327437, 0.16779912, 0.23656955, 0.11059374, 0.60093833],\n",
       "       [0.14411071, 0.13194235, 0.18601732, 0.08696111, 0.47252462],\n",
       "       [0.20585988, 0.18847757, 0.26572281, 0.12422258, 0.67499396]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# G2*F2\n",
    "# X matrix related to factor2\n",
    "np.matmul(np.reshape(G[:,1],(-1,1)),np.reshape(F[1,:],(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14699461, 0.40022956, 0.00674079, 0.31342053, 0.57703959],\n",
       "       [0.15591812, 0.42452603, 0.00715   , 0.33244714, 0.61206955],\n",
       "       [0.05297617, 0.14424086, 0.00242935, 0.11295529, 0.20796237],\n",
       "       [0.13976561, 0.38054679, 0.00640929, 0.29800691, 0.54866154],\n",
       "       [0.05616606, 0.15292612, 0.00257563, 0.11975674, 0.22048453],\n",
       "       [0.16956825, 0.46169194, 0.00777596, 0.36155183, 0.6656543 ],\n",
       "       [0.08282582, 0.225514  , 0.00379818, 0.17660044, 0.32513966],\n",
       "       [0.08986794, 0.24468792, 0.00412111, 0.19161557, 0.35278408],\n",
       "       [0.03254102, 0.08860106, 0.00149225, 0.06938366, 0.12774249],\n",
       "       [0.1359593 , 0.37018316, 0.00623474, 0.28989113, 0.53371954]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# G3*F3\n",
    "# X matrix related to factor3\n",
    "np.matmul(np.reshape(G[:,2],(-1,1)),np.reshape(F[2,:],(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator as op\n",
    "from functools import reduce\n",
    "\n",
    "def nck(n, k):\n",
    "    k = min(k, n-k)\n",
    "    numer = reduce(op.mul, range(n, n-k, -1), 1)\n",
    "    denom = reduce(op.mul, range(1, k+1), 1)\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.8 #probability to ruin a toy\n",
    "q = 1-p\n",
    "n = 8 # number of toys each kid got\n",
    "k = 6 #at least number of toys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_toys_a_kid_ruins_a_day = 0\n",
    "for i in range(k,n+1):\n",
    "    no_toys_a_kid_ruins_a_day = no_toys_a_kid_ruins_a_day + nck(n,i)*(p**i)*(q**(n-i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79691776"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_toys_a_kid_ruins_a_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = no_toys_a_kid_ruins_a_day\n",
    "q1 = 1-p1\n",
    "n1 = 11 # number of kids yudicolus have\n",
    "k1 = 9 # at least number of kids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_kids = 0\n",
    "for i in range(k1,n1+1):\n",
    "    no_kids = no_kids + nck(n1,i)*(p1**i)*(q1**(n1-i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.607163697719032"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_kids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027040137309141496"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balls=26\n",
    "winning=11\n",
    "\n",
    "p = winning/balls\n",
    "q=1-p\n",
    "#a\n",
    "n = 6\n",
    "(1-p)**(n-1)*p #probability to only extract winning in the nth trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3636363636363638"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b #E\n",
    "1/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2231404958677685"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b2 #Var\n",
    "q/(p**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1408170232134729"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "until = 3\n",
    "k = 10 \n",
    "\n",
    "p*q**(until-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# import plotly.graph_objects as go\n",
    "# from ipywidgets import widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('https://raw.githubusercontent.com/yankev/testing/master/datasets/nycflights.csv')\n",
    "# df = df.drop(df.columns[[0]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame([[2013,9,19,1846.0,16.0,2250.0,np.NAN,'DL','N909DL',2391,'JFK','TPA',np.NAN],\n",
    "#                    [2012,2,1,1146.0,0,1350.0,-11,'FL','N969AT',353,'LGA','CAK',65]],columns =\n",
    "#                   ['year','month','day','dep_time','dep_delay','arr_time','arr_delay','carrier','tailnum',\n",
    "#                    'flight','origin','dest','air_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>carrier</th>\n",
       "      <th>tailnum</th>\n",
       "      <th>flight</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>air_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DL</td>\n",
       "      <td>N909DL</td>\n",
       "      <td>2391</td>\n",
       "      <td>JFK</td>\n",
       "      <td>TPA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>N969AT</td>\n",
       "      <td>353</td>\n",
       "      <td>LGA</td>\n",
       "      <td>CAK</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  dep_time  dep_delay  arr_time  arr_delay carrier tailnum  \\\n",
       "0  2013      9   19    1846.0       16.0    2250.0        NaN      DL  N909DL   \n",
       "1  2012      2    1    1146.0        0.0    1350.0      -11.0      FL  N969AT   \n",
       "\n",
       "   flight origin dest  air_time  \n",
       "0    2391    JFK  TPA       NaN  \n",
       "1     353    LGA  CAK      65.0  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import itertools\n",
    "import metpy as mp\n",
    "import metpy.calc as mpcalc\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from scipy import special\n",
    "import ipywidgets as widgets\n",
    "from metpy.units import units\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraction is in UTC time. it gives you results for UTC time. \n",
    "# the true corresponding time in Israel it was 2 or 3 hours later\n",
    "def get_station_props():\n",
    "    station_names = []\n",
    "    station_ids = []\n",
    "    station_latitude = []\n",
    "    station_longitude = []\n",
    "    myUrl = 'https://api.svivaaqm.net/v1/envista/stations/?from=2019-11-01T00:00&to=2019/11/01T00:30'\n",
    "    head = {'Authorization': 'ApiToken {}'.format(myToken), 'envi-data-source': 'MANA'}\n",
    "    response = requests.get(myUrl, headers=head)\n",
    "    j_response = response.json()\n",
    "    for row in j_response:\n",
    "        station_ids.append(row['stationId'])\n",
    "        station_names.append(row['name'])\n",
    "        station_latitude.append(row['location']['latitude'])\n",
    "        station_longitude.append(row['location']['longitude'])\n",
    "    return station_ids,station_names,station_latitude,station_longitude\n",
    "\n",
    "def get_data_by_stationId(from_date, to_date, stationId):\n",
    "    myUrl = 'https://api.svivaaqm.net/v1/envista/stations/'+stationId+'/data?from='+from_date+'&to='+to_date\n",
    "    head = {'Authorization': 'ApiToken {}'.format(myToken), 'envi-data-source': 'MANA'}\n",
    "    response = requests.get(myUrl, headers=head)\n",
    "    return response\n",
    "\n",
    "# use this to get column names and units of the station\n",
    "def get_column_names(stationId):\n",
    "    myUrl = 'https://api.svivaaqm.net/v1/envista/stations/'+stationId+'?from=2019-12-01T00:00&to=2019/12/01T00:06'\n",
    "    head = {'Authorization': 'ApiToken {}'.format(myToken), 'envi-data-source': 'MANA'}\n",
    "    response = requests.get(myUrl, headers=head)\n",
    "    # units\n",
    "    extract = response.json()['monitors']\n",
    "    units = dict()\n",
    "    for e in extract:\n",
    "        units.update({e['name']:e['units']})\n",
    "    column_names = [i + ' [' + j +']' for i, j in units.items()]\n",
    "    return list(units.keys()), column_names\n",
    "\n",
    "\n",
    "def get_dataFrame(dict_train,stationId):\n",
    "    dates = []\n",
    "    for row in dict_train:\n",
    "        dates.append(row['datetime'])\n",
    "\n",
    "    pollutants = []\n",
    "    for row in dict_train:\n",
    "        pollutant = dict()\n",
    "        for p in row['channels']:\n",
    "            pollutant.update({p['name']:p['value']})\n",
    "        pollutants.append(pollutant)\n",
    "\n",
    "    cols, station_columns = get_column_names(str(stationId))\n",
    "\n",
    "    total_list = []\n",
    "    for c in cols: #number of columns(j)\n",
    "        vals = []\n",
    "        for p in pollutants: #number of rows or values(i)\n",
    "            if p[c] is not None:\n",
    "                vals.append(p[c])\n",
    "            else:\n",
    "                vals.append(np.NaN)\n",
    "        total_list.append(vals)\n",
    "\n",
    "    data_df = pd.DataFrame(np.transpose(total_list), index = pd.to_datetime(dates,utc=True).tz_convert('Israel'), columns = station_columns)\n",
    "    \n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "myToken = '71e67c41-8478-4310-9293-196f559493ca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of station names, ids, latitude and longitude\n",
    "station_ids,station_names,station_latitude, station_longitude = get_station_props()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constract a dataframe of station properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_df = pd.DataFrame(np.transpose([station_ids,station_names,station_latitude,station_longitude]), columns = ['station_ids','station_names','station_latitude','station_longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_ids</th>\n",
       "      <th>station_names</th>\n",
       "      <th>station_latitude</th>\n",
       "      <th>station_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>עפולה</td>\n",
       "      <td>32.6033</td>\n",
       "      <td>35.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>עמיאל</td>\n",
       "      <td>32.047</td>\n",
       "      <td>34.7926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>אריאל</td>\n",
       "      <td>32.1035</td>\n",
       "      <td>35.1678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>בר אילן -י''ם</td>\n",
       "      <td>31.7945</td>\n",
       "      <td>35.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>באר שבע</td>\n",
       "      <td>31.2567</td>\n",
       "      <td>34.7813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>465</td>\n",
       "      <td>אלעד</td>\n",
       "      <td>32.0593</td>\n",
       "      <td>34.9517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>467</td>\n",
       "      <td>לב אשדוד</td>\n",
       "      <td>31.7969</td>\n",
       "      <td>34.6483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>468</td>\n",
       "      <td>אביגדור</td>\n",
       "      <td>31.711</td>\n",
       "      <td>34.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>469</td>\n",
       "      <td>תימורים</td>\n",
       "      <td>31.7159</td>\n",
       "      <td>34.7552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>472</td>\n",
       "      <td>נחשולים</td>\n",
       "      <td>32.6139</td>\n",
       "      <td>34.9182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    station_ids  station_names station_latitude station_longitude\n",
       "0             1          עפולה          32.6033            35.291\n",
       "1             2          עמיאל           32.047           34.7926\n",
       "2             3          אריאל          32.1035           35.1678\n",
       "3             5  בר אילן -י''ם          31.7945             35.22\n",
       "4             6        באר שבע          31.2567           34.7813\n",
       "..          ...            ...              ...               ...\n",
       "153         465           אלעד          32.0593           34.9517\n",
       "154         467       לב אשדוד          31.7969           34.6483\n",
       "155         468        אביגדור           31.711            34.745\n",
       "156         469        תימורים          31.7159           34.7552\n",
       "157         472        נחשולים          32.6139           34.9182\n",
       "\n",
       "[158 rows x 4 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all stations info for the last X time by days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data of last x months or days (in LOCAL TIME (now) or UTC time (utcnow)) for a specific station\n",
    "num_days = 30\n",
    "to_time = pd.Timestamp.utcnow().to_pydatetime().strftime('%Y-%m-%dT%H:%M')\n",
    "from_time = (pd.Timestamp.utcnow().to_pydatetime() - relativedelta(days=num_days)).strftime('%Y-%m-%dT%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for SI in str(station_ids[0]):\n",
    "    stationData = get_data_by_stationId(from_time, to_time,SI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stationData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_train = stationData.json()['data']\n",
    "df1 = get_dataFrame(dict_train,SI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SO2 [ppb]</th>\n",
       "      <th>No [ppb]</th>\n",
       "      <th>Nox [ppb]</th>\n",
       "      <th>No2 [ppb]</th>\n",
       "      <th>O3 [ppb]</th>\n",
       "      <th>PM10 [µg/m3]</th>\n",
       "      <th>WS [m/sec]</th>\n",
       "      <th>WD [deg]</th>\n",
       "      <th>Temp [°c]</th>\n",
       "      <th>RH [%]</th>\n",
       "      <th>GSR [w/m2]</th>\n",
       "      <th>StWd [deg]</th>\n",
       "      <th>PM2.5 [µg/m3]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-21 10:55:00+03:00</th>\n",
       "      <td>1.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>13.8</td>\n",
       "      <td>11.4</td>\n",
       "      <td>48.5</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>157.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>974.5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-21 11:00:00+03:00</th>\n",
       "      <td>1.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>11.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>48.3</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>120.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>964.5</td>\n",
       "      <td>16.9</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-21 11:05:00+03:00</th>\n",
       "      <td>1.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>13.3</td>\n",
       "      <td>10.9</td>\n",
       "      <td>46.9</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>134.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>53.0</td>\n",
       "      <td>961.8</td>\n",
       "      <td>22.4</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-21 11:10:00+03:00</th>\n",
       "      <td>1.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>11.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>48.9</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>134.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>921.3</td>\n",
       "      <td>13.6</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-21 11:15:00+03:00</th>\n",
       "      <td>1.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>10.8</td>\n",
       "      <td>8.9</td>\n",
       "      <td>47.3</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>139.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>897.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>-9999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           SO2 [ppb]  No [ppb]  Nox [ppb]  No2 [ppb]  \\\n",
       "2020-04-21 10:55:00+03:00        1.6       2.4       13.8       11.4   \n",
       "2020-04-21 11:00:00+03:00        1.4       1.9       11.5        9.6   \n",
       "2020-04-21 11:05:00+03:00        1.3       2.4       13.3       10.9   \n",
       "2020-04-21 11:10:00+03:00        1.4       2.2       11.5        9.4   \n",
       "2020-04-21 11:15:00+03:00        1.4       1.6       10.8        8.9   \n",
       "\n",
       "                           O3 [ppb]  PM10 [µg/m3]  WS [m/sec]  WD [deg]  \\\n",
       "2020-04-21 10:55:00+03:00      48.5          44.0         2.4     157.0   \n",
       "2020-04-21 11:00:00+03:00      48.3          44.0         2.3     120.0   \n",
       "2020-04-21 11:05:00+03:00      46.9          44.0         1.9     134.0   \n",
       "2020-04-21 11:10:00+03:00      48.9          44.0         2.7     134.0   \n",
       "2020-04-21 11:15:00+03:00      47.3          44.0         2.5     139.0   \n",
       "\n",
       "                           Temp [°c]  RH [%]  GSR [w/m2]  StWd [deg]  \\\n",
       "2020-04-21 10:55:00+03:00       26.0    52.0       974.5        18.6   \n",
       "2020-04-21 11:00:00+03:00       26.0    52.0       964.5        16.9   \n",
       "2020-04-21 11:05:00+03:00       26.3    53.0       961.8        22.4   \n",
       "2020-04-21 11:10:00+03:00       26.2    52.0       921.3        13.6   \n",
       "2020-04-21 11:15:00+03:00       26.0    54.0       897.3        12.9   \n",
       "\n",
       "                           PM2.5 [µg/m3]  \n",
       "2020-04-21 10:55:00+03:00        -9999.0  \n",
       "2020-04-21 11:00:00+03:00        -9999.0  \n",
       "2020-04-21 11:05:00+03:00        -9999.0  \n",
       "2020-04-21 11:10:00+03:00        -9999.0  \n",
       "2020-04-21 11:15:00+03:00        -9999.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
