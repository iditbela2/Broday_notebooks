{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import ipywidgets as widgets\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.impute import MissingIndicator\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM25 = pd.read_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/PM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.date_range(start='2013-01-01 00:00:00', end='2018-12-31 23:00:00', freq='30Min') #one less because the last is always nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = PM25.shape[0]-times.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the last index as it is always nan\n",
    "PM25 = PM25[:-1]\n",
    "times = times[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.6 # how much non-missing values are in the time-series in order to include the station?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced PM25 \n",
    "r_PM25 = PM25[start_year:] \n",
    "idx = r_PM25.notnull().sum(axis = 0)/r_PM25.shape[0]>threshold\n",
    "r_PM25 = r_PM25.loc[:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_PM25.reset_index(inplace=True)\n",
    "r_PM25.drop(labels = 'index',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_PM25['datetime'] = pd.to_datetime(times)\n",
    "r_PM25_withDays = r_PM25.copy()\n",
    "r_PM25_withDays['week day'] = pd.to_datetime(times).dayofweek\n",
    "r_PM25_withDays['month'] = pd.to_datetime(times).month\n",
    "r_PM25_withDays['hour'] = pd.to_datetime(times).hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "AFULA              0.082660\n",
       "ANTOKOLSKY         0.095611\n",
       "HOLON              0.058488\n",
       "IRONID             0.091893\n",
       "KVISH4             0.238214\n",
       "REMEZ              0.135196\n",
       "YAD_LEBANIM        0.372896\n",
       "YEFET_YAFO         0.183843\n",
       "AHUZA_G            0.030295\n",
       "ATZMAUT_B          0.107849\n",
       "KIRYAT_ATA         0.275526\n",
       "KIRYAT_BIALIK      0.308836\n",
       "KIRYAT_BINYAMIN    0.033518\n",
       "KIRYAT_TIVON       0.039347\n",
       "NAVE_SHANAAN       0.041886\n",
       "NESHER             0.152359\n",
       "BAR_ILAN           0.229418\n",
       "EFRATA             0.137630\n",
       "ASHDOD_IGUD        0.078153\n",
       "ASHKELON_SOUTH     0.252325\n",
       "GEDERA             0.097465\n",
       "GVARAAM            0.103921\n",
       "KIRYAT_MALAHI      0.143573\n",
       "NIR_ISRAEL         0.085788\n",
       "ORT                0.233716\n",
       "ROVA_TV            0.320161\n",
       "SDEROT             0.072200\n",
       "SDE_YOAV           0.039633\n",
       "YAHALOM            0.258496\n",
       "BEER_SHEVA         0.144552\n",
       "EAST_NEGEV         0.273140\n",
       "KFAR_MASARIK       0.233612\n",
       "PARDES_HANA        0.263165\n",
       "RAANANA            0.099024\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null percentages\n",
    "r_PM25.shape[1]\n",
    "1-r_PM25.notnull().sum(axis = 0)/r_PM25.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105166"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3575644"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_PM25.shape[0]\n",
    "r_PM25.shape[1]\n",
    "r_PM25.shape[1]*r_PM25.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the division of the CV identical to compare different algorithms. \n",
    "rnd_state_forCV = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of all non-nan indexes, perform 10-fold cross validation.\n",
    "# the test is y_missing. copy r_PM25, put all null inside, and assign values from r_PM25 according to test indexes. \n",
    "# the train is X_missing. copy r_PM25, and assign nans according to test indexes. \n",
    "# the splitting currently doesn't try to preserve the original relative missing intervals\n",
    "# of each feature. maybe I will add it somehow later. \n",
    "\n",
    "def KFold_cross_validation(imp,PM25,k,withDays):\n",
    "    \n",
    "    if withDays:\n",
    "        wd = PM25['week day']\n",
    "        m = PM25['month']\n",
    "        h = PM25['hour']\n",
    "        PM25.drop(['week day','month','hour'],axis=1,inplace=True)\n",
    "        \n",
    "        \n",
    "    kf = KFold(n_splits=k, random_state=rnd_state_forCV, shuffle=True)\n",
    "    not_nan_idx = np.argwhere(PM25.notnull().values)\n",
    "    results = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(not_nan_idx):\n",
    "        np_PM25 = PM25.values\n",
    "        X_missing = PM25.copy()\n",
    "        y_missing = PM25.copy()\n",
    "        \n",
    "        # y_missing \n",
    "        y_missing.iloc[:] = np.nan\n",
    "        np_y_missing = y_missing.values\n",
    "        \n",
    "        # asssign values according to test indexes\n",
    "        rows, cols = zip(*not_nan_idx[test_index])\n",
    "        vals = np_PM25[rows, cols]\n",
    "        np_y_missing[rows, cols] = vals\n",
    "        # turn back to dataframe\n",
    "        y_missing = pd.DataFrame(np_y_missing,columns=PM25.columns)\n",
    "\n",
    "        # X_missing\n",
    "        # assign nans according to test indexes\n",
    "        np_X_missing = X_missing.values\n",
    "        np_X_missing[rows, cols] = np.nan\n",
    "        \n",
    "        # turn back to dataframe\n",
    "        X_missing = pd.DataFrame(np_X_missing,columns=PM25.columns)\n",
    "        \n",
    "        if withDays:\n",
    "            X_missing['week day']=wd\n",
    "            X_missing['hour']=h\n",
    "            X_missing['month']=m\n",
    "        \n",
    "        # mask all missing values\n",
    "        indicator = MissingIndicator(missing_values=np.nan)\n",
    "        mask_missing_values_original = indicator.fit_transform(PM25)\n",
    "        mask_missing_values_all = indicator.fit_transform(X_missing)\n",
    "\n",
    "        # perform fit \n",
    "        imp.fit(X_missing)\n",
    "        imputed_df = imp.transform(X_missing) # impute it\n",
    "        imputed_df = pd.DataFrame(imputed_df, columns=X_missing.columns) #turn it from IterativeImputer object to a dataframe\n",
    "        \n",
    "        if withDays:\n",
    "            imputed_df.drop(['week day','hour','month'],axis = 1, inplace=True)\n",
    "                       \n",
    "        # evaluate\n",
    "        y_train = vals\n",
    "        np_imputed_df = imputed_df.values\n",
    "        y_pred = np_imputed_df[rows, cols]\n",
    "        \n",
    "        # assign results\n",
    "        RMSE = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "        MedianAE = median_absolute_error(y_train, y_pred)\n",
    "        MeanAE = mean_absolute_error(y_train,y_pred)\n",
    "        R2 = r2_score(y_train,y_pred)\n",
    "        results.append([RMSE,MedianAE,MeanAE,R2])\n",
    "               \n",
    "    results = pd.DataFrame(results, columns=['RMSE','MedianAE','MeanAE','R2'])\n",
    "    \n",
    "    return results\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) IterativeImputer with BayesianRidge and ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure about the random_state! plus I've read that no need for CV in random forest.\n",
    "rnd_state_forRF = 0 # I believe I should play with this parameter as well. \n",
    "imp_RF = IterativeImputer(max_iter=5,estimator=ExtraTreesRegressor(n_estimators=10,random_state=rnd_state_forRF),verbose=True) \n",
    "imp_BR = IterativeImputer(max_iter=10,estimator=BayesianRidge(),verbose=True) \n",
    "# try also to change the initial imputer - mean/median/constant...\n",
    "# and n_estimators (number of trees in the forest...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A - without days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_woD_RF = KFold_cross_validation(imp_RF,r_PM25,k=10,withDays=False)\n",
    "results_woD_BR = KFold_cross_validation(imp_BR,r_PM25,k=10,withDays=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MedianAE</th>\n",
       "      <th>MeanAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.276128</td>\n",
       "      <td>4.08</td>\n",
       "      <td>5.739155</td>\n",
       "      <td>0.840807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.432850</td>\n",
       "      <td>4.06</td>\n",
       "      <td>5.744132</td>\n",
       "      <td>0.836131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.288789</td>\n",
       "      <td>4.07</td>\n",
       "      <td>5.748222</td>\n",
       "      <td>0.844457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.384672</td>\n",
       "      <td>4.07</td>\n",
       "      <td>5.732657</td>\n",
       "      <td>0.841935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.580541</td>\n",
       "      <td>4.06</td>\n",
       "      <td>5.754636</td>\n",
       "      <td>0.836096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.978527</td>\n",
       "      <td>4.06</td>\n",
       "      <td>5.708310</td>\n",
       "      <td>0.843317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.436479</td>\n",
       "      <td>4.08</td>\n",
       "      <td>5.752286</td>\n",
       "      <td>0.822759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.458052</td>\n",
       "      <td>4.06</td>\n",
       "      <td>5.748231</td>\n",
       "      <td>0.843511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.773849</td>\n",
       "      <td>4.07</td>\n",
       "      <td>5.746742</td>\n",
       "      <td>0.830450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.289947</td>\n",
       "      <td>4.06</td>\n",
       "      <td>5.728445</td>\n",
       "      <td>0.839699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE  MedianAE    MeanAE        R2\n",
       "0  9.276128      4.08  5.739155  0.840807\n",
       "1  9.432850      4.06  5.744132  0.836131\n",
       "2  9.288789      4.07  5.748222  0.844457\n",
       "3  9.384672      4.07  5.732657  0.841935\n",
       "4  9.580541      4.06  5.754636  0.836096\n",
       "5  8.978527      4.06  5.708310  0.843317\n",
       "6  9.436479      4.08  5.752286  0.822759\n",
       "7  9.458052      4.06  5.748231  0.843511\n",
       "8  9.773849      4.07  5.746742  0.830450\n",
       "9  9.289947      4.06  5.728445  0.839699"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_woD_RF\n",
    "results_woD_RF.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/results_woD_RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MedianAE</th>\n",
       "      <th>MeanAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.146577</td>\n",
       "      <td>4.757204</td>\n",
       "      <td>6.994312</td>\n",
       "      <td>0.727041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.194144</td>\n",
       "      <td>4.789904</td>\n",
       "      <td>7.030386</td>\n",
       "      <td>0.726149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.152302</td>\n",
       "      <td>4.783614</td>\n",
       "      <td>6.997097</td>\n",
       "      <td>0.733775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.985335</td>\n",
       "      <td>4.777705</td>\n",
       "      <td>6.971577</td>\n",
       "      <td>0.742191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.287126</td>\n",
       "      <td>4.785513</td>\n",
       "      <td>6.987615</td>\n",
       "      <td>0.730406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.964026</td>\n",
       "      <td>4.740049</td>\n",
       "      <td>6.946813</td>\n",
       "      <td>0.721794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.894747</td>\n",
       "      <td>4.788714</td>\n",
       "      <td>6.950691</td>\n",
       "      <td>0.718386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.287924</td>\n",
       "      <td>4.753388</td>\n",
       "      <td>6.965011</td>\n",
       "      <td>0.735859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.436219</td>\n",
       "      <td>4.793671</td>\n",
       "      <td>7.043854</td>\n",
       "      <td>0.725499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.814214</td>\n",
       "      <td>4.763854</td>\n",
       "      <td>6.968005</td>\n",
       "      <td>0.740749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMSE  MedianAE    MeanAE        R2\n",
       "0  12.146577  4.757204  6.994312  0.727041\n",
       "1  12.194144  4.789904  7.030386  0.726149\n",
       "2  12.152302  4.783614  6.997097  0.733775\n",
       "3  11.985335  4.777705  6.971577  0.742191\n",
       "4  12.287126  4.785513  6.987615  0.730406\n",
       "5  11.964026  4.740049  6.946813  0.721794\n",
       "6  11.894747  4.788714  6.950691  0.718386\n",
       "7  12.287924  4.753388  6.965011  0.735859\n",
       "8  12.436219  4.793671  7.043854  0.725499\n",
       "9  11.814214  4.763854  6.968005  0.740749"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_woD_BR\n",
    "results_woD_BR.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/results_woD_BR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B - without days, with normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C - with days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_PM25_withDays = r_PM25.copy()\n",
    "r_PM25_withDays['week day'] = pd.to_datetime(times).dayofweek\n",
    "r_PM25_withDays['month'] = pd.to_datetime(times).month\n",
    "r_PM25_withDays['hour'] = pd.to_datetime(times).hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (105166, 37)\n",
      "[IterativeImputer] Change: 6507.59015818498, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 1140.14, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 1018.79, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 587.3800000000001, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 688.1400000000001, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Completing matrix with shape (105166, 37)\n",
      "[IterativeImputer] Completing matrix with shape (105166, 37)\n",
      "[IterativeImputer] Change: 6920.028004507962, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 1164.3000000000004, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 774.63, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 1046.4400000000005, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 574.29, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Completing matrix with shape (105166, 37)\n",
      "[IterativeImputer] Completing matrix with shape (105166, 37)\n",
      "[IterativeImputer] Change: 5643.5520767070575, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 1205.78, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 1118.8300000000004, scaled tolerance: 1.6975 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-448-fbea26ca5fb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_wD_RF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimp_RF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr_PM25_withDays\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwithDays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults_wD_BR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimp_BR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr_PM25_withDays\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwithDays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-442-69846b720839>\u001b[0m in \u001b[0;36mKFold_cross_validation\u001b[0;34m(imp, PM25, k, withDays)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# perform fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mimputed_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_missing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# impute it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mimputed_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputed_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_missing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#turn it from IterativeImputer object to a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/impute/_iterative.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \"\"\"\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/impute/_iterative.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    641\u001b[0m                 Xt, estimator = self._impute_one_feature(\n\u001b[1;32m    642\u001b[0m                     \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_missing_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor_feat_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                     estimator=None, fit_mode=True)\n\u001b[0m\u001b[1;32m    644\u001b[0m                 estimator_triplet = _ImputerTriplet(feat_idx,\n\u001b[1;32m    645\u001b[0m                                                     \u001b[0mneighbor_feat_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/impute/_iterative.py\u001b[0m in \u001b[0;36m_impute_one_feature\u001b[0;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode)\u001b[0m\n\u001b[1;32m    301\u001b[0m             y_train = _safe_indexing(X_filled[:, feat_idx],\n\u001b[1;32m    302\u001b[0m                                      ~missing_row_mask)\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# if no missing values, don't predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 392\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1246\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1247\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_wD_RF = KFold_cross_validation(imp_RF,r_PM25_withDays,k=10,withDays=True)\n",
    "results_wD_BR = KFold_cross_validation(imp_BR,r_PM25_withDays,k=10,withDays=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_wD_RF\n",
    "results_wD_RF.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/results_wD_RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_wD_BR\n",
    "results_wD_BR.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/results_wD_BR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D - with days, with normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind/other met./other pollutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A - iterative imputer - VERY SLOW!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all neighbors. \n",
    "imp_KNN = IterativeImputer(max_iter=1,estimator=KNeighborsRegressor(n_neighbors=r_PM25.shape[0],weights='distance',n_jobs=-1),verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_woD_KNN = KFold_cross_validation(imp_KNN,r_PM25,k=10,withDays=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_woD_KNN\n",
    "results_woD_KNN.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/results_woD_KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B - my KNN implemintation (on rows! not columns!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105166, 34)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_r_PM25 = r_PM25.values\n",
    "np_r_PM25.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with filling rows where ALL columns are nan, with the \n",
    "# mean values suited for the days of week, hour and month. \n",
    "# if starting in 2013, I have 5 rows like that (all 34 stations are missing).\n",
    "# later, the largest missing row is 24 (so 10 values exist). \n",
    "# but, should keep track if changing year. \n",
    "order = np.sort(np.isnan(np_r_PM25).sum(axis=1))\n",
    "num_idx = np.sum(order==34)\n",
    "# num_idx\n",
    "\n",
    "order = np.argsort(np.isnan(np_r_PM25).sum(axis=1))\n",
    "# np_r_PM25[order[-num_idx:],:]\n",
    "idx = order[-num_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_PM25_copy = r_PM25.copy()\n",
    "times_dt = pd.to_datetime(times)\n",
    "r_PM25_copy['datetime'] = pd.to_datetime(times)\n",
    "means_to_impute_by = r_PM25_copy.groupby([r_PM25_copy.datetime.dt.month, r_PM25_copy.datetime.dt.dayofweek, r_PM25_copy.datetime.dt.hour]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(idx)):\n",
    "    np_r_PM25[idx[i],:] = means_to_impute_by.loc[(times_dt[i].month,times_dt[i].dayofweek,times_dt[i].hour),:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the nan values are very problematic, as the shortest distance would be from other \n",
    "# times with lots of nans!!!\n",
    "\n",
    "# I should consider the distance only for non-nan values and divide by the size of the \n",
    "# compared vactors so I give better score (=shorter distance) to larger vectors. \n",
    "# maybe first keep another column with the size of the common elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the begining!\n",
    "\n",
    "def get_distance(row1, row2):   \n",
    "    cond = np.array((np.isnan(row1)) | (np.isnan(row2)))    \n",
    "    # divide the dist by the number of elements compared\n",
    "    dist = distance.cosine(row1[~cond],row2[~cond])/np.sum(~cond) #euclidean/cosine...\n",
    "    return dist\n",
    "\n",
    "def get_neighbors(all_data, imputed_row, num_neighbors):\n",
    "    distances = list()\n",
    "    weights = list()\n",
    "    for row in all_data:\n",
    "        dist = get_distance(imputed_row, row)\n",
    "        distances.append((row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "        weights.append(distances[i][1])\n",
    "    return weights[1:], neighbors[1:] # don't return the imputed row itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort np_r_PM25, so I call the get_all_neighbors function by asc order \n",
    "# of number of nans in a row. \n",
    "order = np.argsort(np.isnan(np_r_PM25).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51199c60348d41ba9d6fb8158ac1763d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105166), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imputed = np_r_PM25.copy()\n",
    "imputed = imputed[order,:] # imputed is sorted by number of nan values in a row (asc)\n",
    "num_neighbors = imputed.shape[0]\n",
    "\n",
    "for i,row in enumerate(tqdm(imputed)): # perform impute per row, to save time. \n",
    "    nan_ind = np.argwhere(np.isnan(row))\n",
    "    weights, neighbors = get_neighbors(imputed, row, num_neighbors)\n",
    "\n",
    "    weights = [1/x for x in weights]\n",
    "    weights = weights/np.sum(weights)\n",
    "    \n",
    "    fill_by = np.squeeze(np.array(neighbors)[:,nan_ind])\n",
    "    # turn nan to zeros and \n",
    "    fill_by[np.isnan(fill_by)] = 0\n",
    "    imputed[i,nan_ind] = np.dot(weights,fill_by).reshape(-1, 1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the end, run something like that:\n",
    "np_r_PM25[order,:] = imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed = np_r_PM25.copy()\n",
    "imputed = imputed[order,:] # imputed is sorted by number of nan values in a row (asc)\n",
    "num_neighbors = imputed.shape[0]\n",
    "\n",
    "num_neighbors = imputed.shape[0]\n",
    "row = imputed[19396,:]\n",
    "nan_ind = np.argwhere(np.isnan(row))\n",
    "nan_ind\n",
    "\n",
    "weights, neighbors = get_neighbors(imputed, row, num_neighbors)\n",
    "\n",
    "weights = [1/x for x in weights]\n",
    "weights = weights/np.sum(weights)\n",
    "\n",
    "np.shape(weights)\n",
    "\n",
    "fill_by = np.squeeze(np.array(neighbors)[:,nan_ind])\n",
    "\n",
    "# turn nan to zeros and \n",
    "fill_by[np.isnan(fill_by)] = 0\n",
    "\n",
    "np.shape(fill_by)\n",
    "\n",
    "np.shape(np.dot(weights,fill_by).reshape(-1, 1))\n",
    "\n",
    "imputed[19396,nan_ind] = np.dot(weights,fill_by).reshape(-1, 1)\n",
    "\n",
    "imputed[19396,nan_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) ARIMA/LSTM/Prophet for 1-? missing time-steps (short intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) The simplest interpolation for 1-? missing time-steps (short intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA might be problematic since I need to tune the parameters all the time. Does LSTM \n",
    "# require less parameters? in addition, I could predic short intervals but then continue \n",
    "# to predict with the LSTM with the long intervals as -1, as described in machinelearning\n",
    "# mastery. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5) Runing models 1-2 again with the short-interval imputed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# others\n",
    "# https://impyute.readthedocs.io/en/latest/index.html\n",
    "# https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779\n",
    "# statsmodels MICE\n",
    "# datawig \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6) Statistical imputation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trash\n",
    "\n",
    "s = pd.Series(tuple(map(tuple, not_nan_idx[test_index])))\n",
    "vals = s.apply(lambda xy: r_PM25.iloc[xy[0],xy[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM25=r_PM25\n",
    "k=2\n",
    "withDays=False\n",
    "\n",
    "kf = KFold(n_splits=k, random_state=0, shuffle=True)\n",
    "not_nan_idx = np.argwhere(PM25.notnull().values)\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      1,       3,       4, ..., 1754019, 1754021, 1754024])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([      0,       2,       6, ..., 1754023, 1754025, 1754026])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([      0,       2,       6, ..., 1754023, 1754025, 1754026])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([      1,       3,       4, ..., 1754019, 1754021, 1754024])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(not_nan_idx):\n",
    "        train_index\n",
    "        test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (52606, 39)\n",
      "[IterativeImputer] Change: 6112.810739330168, scaled tolerance: 1.133 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/impute/_iterative.py:670: ConvergenceWarning:\n",
      "\n",
      "[IterativeImputer] Early stopping criterion not reached.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IterativeImputer(estimator=ExtraTreesRegressor(n_estimators=10, random_state=0),\n",
       "                 max_iter=1, verbose=True)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (52606, 39)\n"
     ]
    }
   ],
   "source": [
    "np_PM25 = PM25.values\n",
    "X_missing = PM25.copy()\n",
    "y_missing = PM25.copy()\n",
    "\n",
    "# y_missing \n",
    "y_missing.iloc[:] = np.nan\n",
    "np_y_missing = y_missing.values\n",
    "\n",
    "# asssign values according to test indexes\n",
    "rows, cols = zip(*not_nan_idx[test_index])\n",
    "vals = np_PM25[rows, cols]\n",
    "np_y_missing[rows, cols] = vals\n",
    "# turn back to dataframe\n",
    "y_missing = pd.DataFrame(np_y_missing,columns=PM25.columns)\n",
    "\n",
    "# X_missing\n",
    "# assign nans according to test indexes\n",
    "np_X_missing = X_missing.values\n",
    "np_X_missing[rows, cols] = np.nan\n",
    "\n",
    "# turn back to dataframe\n",
    "X_missing = pd.DataFrame(np_X_missing,columns=PM25.columns)\n",
    "\n",
    "# mask all missing values\n",
    "indicator = MissingIndicator(missing_values=np.nan)\n",
    "mask_missing_values_original = indicator.fit_transform(PM25)\n",
    "mask_missing_values_all = indicator.fit_transform(X_missing)\n",
    "\n",
    "# perform fit \n",
    "imp.fit(X_missing)\n",
    "imputed_df = imp.transform(X_missing) # impute it\n",
    "imputed_df = pd.DataFrame(imputed_df, columns=X_missing.columns) #turn it from IterativeImputer object to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "# y_train = inverse_y_missing.values\n",
    "y_train = vals\n",
    "\n",
    "# y_pred = inverse_imputed_df.mask(~mask).values\n",
    "np_imputed_df = imputed_df.values\n",
    "y_pred = np_imputed_df[rows, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877013,)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(877013,)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign results\n",
    "RMSE = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "MedianAE = median_absolute_error(y_train, y_pred)\n",
    "MeanAE = mean_absolute_error(y_train,y_pred)\n",
    "R2 = r2_score(y_train,y_pred)\n",
    "# results.append([RMSE,MedianAE,MeanAE,R2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign results\n",
    "RMSE = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "MedianAE = median_absolute_error(y_train, y_pred)\n",
    "MeanAE = mean_absolute_error(y_train,y_pred)\n",
    "R2 = r2_score(y_train,y_pred)\n",
    "results.append([RMSE,MedianAE,MeanAE,R2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12.065151202546158,\n",
       "  4.540000000000001,\n",
       "  6.837151125467923,\n",
       "  0.5649296791889007]]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # do I need to sort all rows so I start with imputing the row with the smallest number \n",
    "# # of missing values? I think so. \n",
    "\n",
    "# # for i,row in enumerate(np_r_PM25):  \n",
    "# #     # euclidean\n",
    "# #     distance.cdist(np_r_PM25, row.reshape(-1, 1).T, lambda u, v: np.sqrt(np.nansum((u-v)**2)))\n",
    "# #     print(i)\n",
    "# # each chunk I get, is an array of all distances of row i with all other rows.\n",
    "# # this is why in the first chunk 0 is first, in the second chunk 0 is second...\n",
    "# # Once distances are calculated, we must sort all of the records in the training \n",
    "# # dataset by their distance to the new data (the desired row). \n",
    "# # We can then select the top k to return as the most similar neighbors. \n",
    "\n",
    "\n",
    "# def get_distance(all_data, imputed_row):\n",
    "\n",
    "#     # when I want to compute it to all elements in the row, including nans:\n",
    "#     dist = distance.cdist(all_data, imputed_row.reshape(-1, 1).T, lambda u, v: np.sqrt(np.nansum((u-v)**2)))\n",
    "#     return dist\n",
    "    \n",
    "# # Locate the most similar neighbors of a row. \n",
    "# # all_data = np_r_PM25\n",
    "# # imputed_row = the current row you want to impute. \n",
    "\n",
    "# def get_neighbors(all_data, imputed_row, num_neighbors):\n",
    "#     dist = get_distance(all_data, imputed_row)\n",
    "#     distances = list(zip(np_r_PM25, dist))    \n",
    "#     distances.sort(key=lambda tup: tup[1])\n",
    "#     neighbors = list()\n",
    "#     for i in range(num_neighbors):\n",
    "#         neighbors.append(distances[i][0])\n",
    "#     return neighbors\n",
    "\n",
    "\n",
    "# # # get_all_neighbors weigh all the neighbors. \n",
    "# # # so no need to sort\n",
    "# # def get_all_neighbors(all_data, imputed_row):\n",
    "# #     dist,no_elements = get_distance(all_data, imputed_row)\n",
    "    \n",
    "# #     distances = list(zip(np_r_PM25, dist, no_elements))\n",
    "\n",
    "# #     return neighbors\n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "# #     distance.cdist(np.delete(np_r_PM25, i,axis=0), row.reshape(-1, 1).T, lambda u, v: np.dot(u, v)/(np.linalg.norm(u)*np.linalg.norm(v)))\n",
    "# #     distance.cdist(np.delete(np_r_PM25, i,axis=0), row.reshape(-1, 1).T, 'cosine') #euclidean\n",
    "\n",
    "# # dot(a, b)/(norm(a)*norm(b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
