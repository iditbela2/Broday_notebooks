{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import ipywidgets as widgets\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.impute import MissingIndicator\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM25 = pd.read_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/PM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.date_range(start='2013-01-01 00:00:00', end='2018-12-31 23:00:00', freq='30Min') #one less because the last is always nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = PM25.shape[0]-times.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the last index as it is always nan\n",
    "PM25 = PM25[:-1]\n",
    "times = times[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.6 # how much non-missing values are in the time-series in order to include the station?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced PM25 \n",
    "r_PM25 = PM25[start_year:] \n",
    "idx = r_PM25.notnull().sum(axis = 0)/r_PM25.shape[0]>threshold\n",
    "r_PM25 = r_PM25.loc[:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_PM25.reset_index(inplace=True)\n",
    "r_PM25.drop(labels = 'index',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_PM25['datetime'] = pd.to_datetime(times)\n",
    "r_PM25_withDays = r_PM25.copy()\n",
    "r_PM25_withDays['week day'] = pd.to_datetime(times).dayofweek\n",
    "r_PM25_withDays['month'] = pd.to_datetime(times).month\n",
    "r_PM25_withDays['hour'] = pd.to_datetime(times).hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "AFULA              0.082660\n",
       "ANTOKOLSKY         0.095611\n",
       "HOLON              0.058488\n",
       "IRONID             0.091893\n",
       "KVISH4             0.238214\n",
       "REMEZ              0.135196\n",
       "YAD_LEBANIM        0.372896\n",
       "YEFET_YAFO         0.183843\n",
       "AHUZA_G            0.030295\n",
       "ATZMAUT_B          0.107849\n",
       "KIRYAT_ATA         0.275526\n",
       "KIRYAT_BIALIK      0.308836\n",
       "KIRYAT_BINYAMIN    0.033518\n",
       "KIRYAT_TIVON       0.039347\n",
       "NAVE_SHANAAN       0.041886\n",
       "NESHER             0.152359\n",
       "BAR_ILAN           0.229418\n",
       "EFRATA             0.137630\n",
       "ASHDOD_IGUD        0.078153\n",
       "ASHKELON_SOUTH     0.252325\n",
       "GEDERA             0.097465\n",
       "GVARAAM            0.103921\n",
       "KIRYAT_MALAHI      0.143573\n",
       "NIR_ISRAEL         0.085788\n",
       "ORT                0.233716\n",
       "ROVA_TV            0.320161\n",
       "SDEROT             0.072200\n",
       "SDE_YOAV           0.039633\n",
       "YAHALOM            0.258496\n",
       "BEER_SHEVA         0.144552\n",
       "EAST_NEGEV         0.273140\n",
       "KFAR_MASARIK       0.233612\n",
       "PARDES_HANA        0.263165\n",
       "RAANANA            0.099024\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null percentages\n",
    "r_PM25.shape[1]\n",
    "1-r_PM25.notnull().sum(axis = 0)/r_PM25.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105166"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3575644"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_PM25.shape[0]\n",
    "r_PM25.shape[1]\n",
    "r_PM25.shape[1]*r_PM25.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the division of the CV identical to compare different algorithms. \n",
    "rnd_state_forCV = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of all non-nan indexes, perform 10-fold cross validation.\n",
    "# the test is y_missing. copy r_PM25, put all null inside, and assign values from r_PM25 according to test indexes. \n",
    "# the train is X_missing. copy r_PM25, and assign nans according to test indexes. \n",
    "# the splitting currently doesn't try to preserve the original relative missing intervals\n",
    "# of each feature. maybe I will add it somehow later. \n",
    "\n",
    "def KFold_cross_validation(imp,PM25,k,withDays):\n",
    "    \n",
    "    if withDays:\n",
    "        wd = PM25['week day']\n",
    "        m = PM25['month']\n",
    "        h = PM25['hour']\n",
    "        PM25.drop(['week day','month','hour'],axis=1,inplace=True)\n",
    "        \n",
    "        \n",
    "    kf = KFold(n_splits=k, random_state=rnd_state_forCV, shuffle=True)\n",
    "    not_nan_idx = np.argwhere(PM25.notnull().values)\n",
    "    results = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(not_nan_idx):\n",
    "        np_PM25 = PM25.values\n",
    "        X_missing = PM25.copy()\n",
    "        y_missing = PM25.copy()\n",
    "        \n",
    "        # y_missing \n",
    "        y_missing.iloc[:] = np.nan\n",
    "        np_y_missing = y_missing.values\n",
    "        \n",
    "        # asssign values according to test indexes\n",
    "        rows, cols = zip(*not_nan_idx[test_index])\n",
    "        vals = np_PM25[rows, cols]\n",
    "        np_y_missing[rows, cols] = vals\n",
    "        # turn back to dataframe\n",
    "        y_missing = pd.DataFrame(np_y_missing,columns=PM25.columns)\n",
    "\n",
    "        # X_missing\n",
    "        # assign nans according to test indexes\n",
    "        np_X_missing = X_missing.values\n",
    "        np_X_missing[rows, cols] = np.nan\n",
    "        \n",
    "        # turn back to dataframe\n",
    "        X_missing = pd.DataFrame(np_X_missing,columns=PM25.columns)\n",
    "        \n",
    "        if withDays:\n",
    "            X_missing['week day']=wd\n",
    "            X_missing['hour']=h\n",
    "            X_missing['month']=m\n",
    "        \n",
    "        # perform fit \n",
    "        imp.fit(X_missing)\n",
    "        imputed_df = imp.transform(X_missing) # impute it\n",
    "        imputed_df = pd.DataFrame(imputed_df, columns=X_missing.columns) #turn it from IterativeImputer object to a dataframe\n",
    "        \n",
    "        if withDays:\n",
    "            imputed_df.drop(['week day','hour','month'],axis = 1, inplace=True)\n",
    "                       \n",
    "        # evaluate\n",
    "        y_train = vals\n",
    "        np_imputed_df = imputed_df.values\n",
    "        y_pred = np_imputed_df[rows, cols]\n",
    "        \n",
    "        # assign results\n",
    "        RMSE = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "        MedianAE = median_absolute_error(y_train, y_pred)\n",
    "        MeanAE = mean_absolute_error(y_train,y_pred)\n",
    "        R2 = r2_score(y_train,y_pred)\n",
    "        results.append([RMSE,MedianAE,MeanAE,R2])\n",
    "               \n",
    "    results = pd.DataFrame(results, columns=['RMSE','MedianAE','MeanAE','R2'])\n",
    "    \n",
    "    return results\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) IterativeImputer with BayesianRidge and ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure about the random_state! plus I've read that no need for CV in random forest.\n",
    "rnd_state_forRF = 0 # I believe I should play with this parameter as well. \n",
    "imp_RF = IterativeImputer(max_iter=10,estimator=ExtraTreesRegressor(n_estimators=30,random_state=rnd_state_forRF),verbose=True) \n",
    "imp_BR = IterativeImputer(max_iter=20,estimator=BayesianRidge(),verbose=True) \n",
    "# try also to change the initial imputer - mean/median/constant...\n",
    "# and n_estimators (number of trees in the forest...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A - without days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_woD_RF = KFold_cross_validation(imp_RF,r_PM25,k=10,withDays=False)\n",
    "results_woD_BR = KFold_cross_validation(imp_BR,r_PM25,k=10,withDays=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MedianAE</th>\n",
       "      <th>MeanAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.276128</td>\n",
       "      <td>4.08</td>\n",
       "      <td>5.739155</td>\n",
       "      <td>0.840807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.432850</td>\n",
       "      <td>4.06</td>\n",
       "      <td>5.744132</td>\n",
       "      <td>0.836131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.288789</td>\n",
       "      <td>4.07</td>\n",
       "      <td>5.748222</td>\n",
       "      <td>0.844457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.384672</td>\n",
       "      <td>4.07</td>\n",
       "      <td>5.732657</td>\n",
       "      <td>0.841935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.580541</td>\n",
       "      <td>4.06</td>\n",
       "      <td>5.754636</td>\n",
       "      <td>0.836096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.978527</td>\n",
       "      <td>4.06</td>\n",
       "      <td>5.708310</td>\n",
       "      <td>0.843317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.436479</td>\n",
       "      <td>4.08</td>\n",
       "      <td>5.752286</td>\n",
       "      <td>0.822759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.458052</td>\n",
       "      <td>4.06</td>\n",
       "      <td>5.748231</td>\n",
       "      <td>0.843511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.773849</td>\n",
       "      <td>4.07</td>\n",
       "      <td>5.746742</td>\n",
       "      <td>0.830450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.289947</td>\n",
       "      <td>4.06</td>\n",
       "      <td>5.728445</td>\n",
       "      <td>0.839699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE  MedianAE    MeanAE        R2\n",
       "0  9.276128      4.08  5.739155  0.840807\n",
       "1  9.432850      4.06  5.744132  0.836131\n",
       "2  9.288789      4.07  5.748222  0.844457\n",
       "3  9.384672      4.07  5.732657  0.841935\n",
       "4  9.580541      4.06  5.754636  0.836096\n",
       "5  8.978527      4.06  5.708310  0.843317\n",
       "6  9.436479      4.08  5.752286  0.822759\n",
       "7  9.458052      4.06  5.748231  0.843511\n",
       "8  9.773849      4.07  5.746742  0.830450\n",
       "9  9.289947      4.06  5.728445  0.839699"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_woD_RF\n",
    "results_woD_RF.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/results_woD_RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MedianAE</th>\n",
       "      <th>MeanAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.146577</td>\n",
       "      <td>4.757204</td>\n",
       "      <td>6.994312</td>\n",
       "      <td>0.727041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.194144</td>\n",
       "      <td>4.789904</td>\n",
       "      <td>7.030386</td>\n",
       "      <td>0.726149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.152302</td>\n",
       "      <td>4.783614</td>\n",
       "      <td>6.997097</td>\n",
       "      <td>0.733775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.985335</td>\n",
       "      <td>4.777705</td>\n",
       "      <td>6.971577</td>\n",
       "      <td>0.742191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.287126</td>\n",
       "      <td>4.785513</td>\n",
       "      <td>6.987615</td>\n",
       "      <td>0.730406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.964026</td>\n",
       "      <td>4.740049</td>\n",
       "      <td>6.946813</td>\n",
       "      <td>0.721794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.894747</td>\n",
       "      <td>4.788714</td>\n",
       "      <td>6.950691</td>\n",
       "      <td>0.718386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.287924</td>\n",
       "      <td>4.753388</td>\n",
       "      <td>6.965011</td>\n",
       "      <td>0.735859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.436219</td>\n",
       "      <td>4.793671</td>\n",
       "      <td>7.043854</td>\n",
       "      <td>0.725499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.814214</td>\n",
       "      <td>4.763854</td>\n",
       "      <td>6.968005</td>\n",
       "      <td>0.740749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMSE  MedianAE    MeanAE        R2\n",
       "0  12.146577  4.757204  6.994312  0.727041\n",
       "1  12.194144  4.789904  7.030386  0.726149\n",
       "2  12.152302  4.783614  6.997097  0.733775\n",
       "3  11.985335  4.777705  6.971577  0.742191\n",
       "4  12.287126  4.785513  6.987615  0.730406\n",
       "5  11.964026  4.740049  6.946813  0.721794\n",
       "6  11.894747  4.788714  6.950691  0.718386\n",
       "7  12.287924  4.753388  6.965011  0.735859\n",
       "8  12.436219  4.793671  7.043854  0.725499\n",
       "9  11.814214  4.763854  6.968005  0.740749"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_woD_BR\n",
    "results_woD_BR.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/results_woD_BR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B - without days, with normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C - with days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_PM25_withDays = r_PM25.copy()\n",
    "r_PM25_withDays['week day'] = pd.to_datetime(times).dayofweek\n",
    "r_PM25_withDays['month'] = pd.to_datetime(times).month\n",
    "r_PM25_withDays['hour'] = pd.to_datetime(times).hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_wD_RF = KFold_cross_validation(imp_RF,r_PM25_withDays,k=10,withDays=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_PM25_withDays = r_PM25.copy()\n",
    "r_PM25_withDays['week day'] = pd.to_datetime(times).dayofweek\n",
    "r_PM25_withDays['month'] = pd.to_datetime(times).month\n",
    "r_PM25_withDays['hour'] = pd.to_datetime(times).hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (105166, 37)\n",
      "[IterativeImputer] Change: 6370.989565900771, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 969.4149125965786, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 576.5752099832307, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 314.0645142393083, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 322.1620220333494, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 591.9714768692887, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 402.6942882366628, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 227.65040323712557, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 255.33190960520187, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 68.29994123160066, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 24.690867515296304, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 31.06321102042409, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 26.95427791276279, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 22.64216516846409, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 19.185144737520204, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 16.50235089626574, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 14.405141124034174, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 12.739126735933382, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 11.392685803496363, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 10.286770749578864, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 9.36504973382307, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 8.586788922144365, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 7.922033725204869, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 7.348382617363825, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 6.848812813307688, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 6.410195276412878, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 6.022264763294743, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 5.676893934069142, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 5.367573828252375, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 5.089036442468569, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 4.8369767554867735, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 4.607845284076802, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 4.398691399223196, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 4.207043649296168, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 4.030817375720744, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 3.8682426772056715, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 3.717807769356625, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 3.5782140214202514, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 3.4483400044447308, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 3.32721251403359, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 3.223919697886913, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 3.1884992753618633, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 3.153088869443394, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 3.117706811507759, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 3.082370389354338, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 3.0470959216594053, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 3.011898824978374, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 2.9767936736746776, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 2.9417942544886273, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 2.906913613821814, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Completing matrix with shape (105166, 37)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-297-ab8798fdcf45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_wD_BR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimp_BR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr_PM25_withDays\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwithDays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-291-ad103f977e42>\u001b[0m in \u001b[0;36mKFold_cross_validation\u001b[0;34m(imp, PM25, k, withDays)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# perform fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mimputed_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_missing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# impute it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mimputed_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputed_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_missing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#turn it from IterativeImputer object to a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/impute/_iterative.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0mestimator_triplet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbor_feat_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator_triplet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m                 \u001b[0mfit_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m             )\n\u001b[1;32m    713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mimputations_per_round\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/impute/_iterative.py\u001b[0m in \u001b[0;36m_impute_one_feature\u001b[0;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 random_state=self.random_state_)\n\u001b[1;32m    335\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0mimputed_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m             imputed_values = np.clip(imputed_values,\n\u001b[1;32m    338\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_min_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, return_std)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mStandard\u001b[0m \u001b[0mdeviation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpredictive\u001b[0m \u001b[0mdistribution\u001b[0m \u001b[0mof\u001b[0m \u001b[0mquery\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \"\"\"\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0my_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_std\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0my_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 220\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_wD_BR = KFold_cross_validation(imp_BR,r_PM25_withDays,k=10,withDays=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MedianAE</th>\n",
       "      <th>MeanAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.891562</td>\n",
       "      <td>3.92</td>\n",
       "      <td>5.534868</td>\n",
       "      <td>0.853733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.149023</td>\n",
       "      <td>3.91</td>\n",
       "      <td>5.548026</td>\n",
       "      <td>0.845844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.096198</td>\n",
       "      <td>3.92</td>\n",
       "      <td>5.541519</td>\n",
       "      <td>0.850840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.082441</td>\n",
       "      <td>3.92</td>\n",
       "      <td>5.530160</td>\n",
       "      <td>0.851952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.146131</td>\n",
       "      <td>3.92</td>\n",
       "      <td>5.526155</td>\n",
       "      <td>0.850623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.726580</td>\n",
       "      <td>3.90</td>\n",
       "      <td>5.507559</td>\n",
       "      <td>0.851987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.026643</td>\n",
       "      <td>3.92</td>\n",
       "      <td>5.541228</td>\n",
       "      <td>0.837821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.909576</td>\n",
       "      <td>3.92</td>\n",
       "      <td>5.532779</td>\n",
       "      <td>0.861135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.330047</td>\n",
       "      <td>3.92</td>\n",
       "      <td>5.543148</td>\n",
       "      <td>0.845498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.908671</td>\n",
       "      <td>3.91</td>\n",
       "      <td>5.527290</td>\n",
       "      <td>0.852587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE  MedianAE    MeanAE        R2\n",
       "0  8.891562      3.92  5.534868  0.853733\n",
       "1  9.149023      3.91  5.548026  0.845844\n",
       "2  9.096198      3.92  5.541519  0.850840\n",
       "3  9.082441      3.92  5.530160  0.851952\n",
       "4  9.146131      3.92  5.526155  0.850623\n",
       "5  8.726580      3.90  5.507559  0.851987\n",
       "6  9.026643      3.92  5.541228  0.837821\n",
       "7  8.909576      3.92  5.532779  0.861135\n",
       "8  9.330047      3.92  5.543148  0.845498\n",
       "9  8.908671      3.91  5.527290  0.852587"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_wD_RF\n",
    "results_wD_RF.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/results_wD_RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MedianAE</th>\n",
       "      <th>MeanAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.158469</td>\n",
       "      <td>4.748910</td>\n",
       "      <td>6.987025</td>\n",
       "      <td>0.726506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.090359</td>\n",
       "      <td>4.771156</td>\n",
       "      <td>6.990287</td>\n",
       "      <td>0.730790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.276467</td>\n",
       "      <td>4.774440</td>\n",
       "      <td>7.002976</td>\n",
       "      <td>0.728307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.019256</td>\n",
       "      <td>4.780598</td>\n",
       "      <td>6.978572</td>\n",
       "      <td>0.740730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.290798</td>\n",
       "      <td>4.755746</td>\n",
       "      <td>6.963742</td>\n",
       "      <td>0.730245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.957039</td>\n",
       "      <td>4.712760</td>\n",
       "      <td>6.909068</td>\n",
       "      <td>0.722118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.910672</td>\n",
       "      <td>4.785016</td>\n",
       "      <td>6.948598</td>\n",
       "      <td>0.717632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.271235</td>\n",
       "      <td>4.737253</td>\n",
       "      <td>6.951292</td>\n",
       "      <td>0.736576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.365174</td>\n",
       "      <td>4.775569</td>\n",
       "      <td>7.010698</td>\n",
       "      <td>0.728627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.850018</td>\n",
       "      <td>4.763862</td>\n",
       "      <td>6.965597</td>\n",
       "      <td>0.739175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMSE  MedianAE    MeanAE        R2\n",
       "0  12.158469  4.748910  6.987025  0.726506\n",
       "1  12.090359  4.771156  6.990287  0.730790\n",
       "2  12.276467  4.774440  7.002976  0.728307\n",
       "3  12.019256  4.780598  6.978572  0.740730\n",
       "4  12.290798  4.755746  6.963742  0.730245\n",
       "5  11.957039  4.712760  6.909068  0.722118\n",
       "6  11.910672  4.785016  6.948598  0.717632\n",
       "7  12.271235  4.737253  6.951292  0.736576\n",
       "8  12.365174  4.775569  7.010698  0.728627\n",
       "9  11.850018  4.763862  6.965597  0.739175"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_wD_BR\n",
    "results_wD_BR.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/results_wD_BR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D - with days, with normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind/other met./other pollutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A - iterative imputer - VERY SLOW!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all neighbors. \n",
    "imp_KNN = IterativeImputer(max_iter=1,estimator=KNeighborsRegressor(n_neighbors=r_PM25.shape[0],weights='distance',n_jobs=-1),verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_woD_KNN = KFold_cross_validation(imp_KNN,r_PM25,k=10,withDays=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_woD_KNN\n",
    "results_woD_KNN.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/results_woD_KNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B - my KNN implemintation (on rows! not columns!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105166, 34)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_PM25_copy = r_PM25.copy()\n",
    "np_r_PM25 = r_PM25_copy.values\n",
    "np_r_PM25.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with filling rows where ALL columns are nan, with the \n",
    "# mean values suited for the days of week, hour and month. \n",
    "# if starting in 2013, I have 5 rows like that (all 34 stations are missing).\n",
    "# later, the largest missing row is 24 (so 10 stations exist). \n",
    "# but, should keep track if changing year !!\n",
    "\n",
    "order = np.sort(np.isnan(np_r_PM25).sum(axis=1))\n",
    "num_idx = np.sum(order==34)\n",
    "# num_idx\n",
    "\n",
    "order = np.argsort(np.isnan(np_r_PM25).sum(axis=1))\n",
    "# np_r_PM25[order[-num_idx:],:]\n",
    "idx = order[-num_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_dt = pd.to_datetime(times)\n",
    "r_PM25_copy['datetime'] = pd.to_datetime(times)\n",
    "means_to_impute_by = r_PM25_copy.groupby([r_PM25_copy.datetime.dt.month, r_PM25_copy.datetime.dt.dayofweek, r_PM25_copy.datetime.dt.hour]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(idx)):\n",
    "    np_r_PM25[idx[i],:] = means_to_impute_by.loc[(times_dt[i].month,times_dt[i].dayofweek,times_dt[i].hour),:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distances\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the nan values are very problematic, as the shortest distance would be from other \n",
    "# times with lots of nans!!!\n",
    "\n",
    "# I should consider the distance only for non-nan values and divide by the size of the \n",
    "# compared vactors so I give better score (=shorter distance) to larger vectors. \n",
    "# maybe first keep another column with the size of the common elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = r_PM25.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_corrMatrix = corrMatrix.values\n",
    "# corrMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_distance(all_data, idx, j, num_neighbors, all_data_mask_nans, all_data_mask_total, np_corrMatrix):           \n",
    "    dist = distance.cdist(all_data_mask_nans, ((1/np_corrMatrix[:,j])*(all_data_mask_nans[idx,:].reshape(-1, 1))).T, metric='euclidean') \n",
    "#     dist = distance.cdist(all_data_mask_nans, all_data_mask_nans[idx,:].reshape(-1, 1).T, metric='cosine') #cosine \n",
    "\n",
    "    # I think if its cosine the corr is just multiplied and if euclidean the corr^2. not sure. \n",
    "#     dist = distance.cdist(all_data_mask_nans, all_data_mask_nans[idx,:].reshape(-1, 1).T, lambda u, v: np.sqrt(np.nansum((u-v)**2)))\n",
    "#     dist = distance.cdist(all_data_mask_nans, all_data_mask_nans[idx,:].reshape(-1, 1).T, lambda u, v: 1-np.dot(u,v)/(np.linalg.norm(u)*np.linalg.norm(v)))\n",
    "    \n",
    "    length = np.dot(all_data_mask_total, all_data_mask_total[idx,:].reshape(-1, 1))\n",
    "    \n",
    "    return np.delete(dist/length, idx) #return everything but distance with itself\n",
    "\n",
    "# zero = they are very similar(zero angle, cos=1, 1-cos=0). one = they are different. \n",
    "\n",
    "def get_neighbors(all_data, idx, j, num_neighbors, all_data_mask_nans, all_data_mask_total, np_corrMatrix):\n",
    "#     weights = list()\n",
    "    dist = get_distance(all_data, idx, j, num_neighbors, all_data_mask_nans, all_data_mask_total, np_corrMatrix)\n",
    "#     distances = list(zip(all_data, dist))    \n",
    "#     distances.sort(key=lambda tup: tup[1])\n",
    "#     neighbors = list()\n",
    "#     for i in range(num_neighbors):\n",
    "#         neighbors.append(distances[i][0])\n",
    "#         weights.append(distances[i][1])\n",
    "\n",
    "    return np.array(dist), np.delete(all_data, idx, axis=0) # don't return the imputed row itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort np_r_PM25, so I call the get_all_neighbors function by asc order \n",
    "# of number of nans in a row. \n",
    "order = np.argsort(np.isnan(np_r_PM25).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed = np_r_PM25.copy()\n",
    "imputed = imputed[order,:] # imputed is sorted by number of nan values in a row (asc)\n",
    "num_neighbors = imputed.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_mask_nans = imputed.copy()\n",
    "all_data_mask_total = imputed.copy()\n",
    "\n",
    "mask_nans = np.isnan(imputed)\n",
    "\n",
    "all_data_mask_nans[mask_nans]=0\n",
    "all_data_mask_total[mask_nans]=0\n",
    "all_data_mask_total[~mask_nans]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b152cba6b2bd4cc2a4ab6703cfb4dbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105166), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "get_neighbors() missing 2 required positional arguments: 'all_data_mask_total' and 'np_corrMatrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-434-39b1c388d7f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnan_ind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnan_ind\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_data_mask_nans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_data_mask_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mfill_by\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: get_neighbors() missing 2 required positional arguments: 'all_data_mask_total' and 'np_corrMatrix'"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(imputed))): # perform impute per row, to save time. \n",
    "    nan_ind = np.argwhere(mask_nans[i,:])\n",
    "    if nan_ind.any():\n",
    "        for j in nan_ind:\n",
    "            weights, neighbors = get_neighbors(imputed, i, j, num_neighbors, all_data_mask_nans, all_data_mask_total, np_corrMatrix)    \n",
    "            \n",
    "            fill_by = np.squeeze(neighbors[:,j])\n",
    "            # turn nan to zeros so it won't be accounted for \n",
    "            \n",
    "            weights[np.isnan(fill_by)] = 0\n",
    "            fill_by[np.isnan(fill_by)] = 0\n",
    "            \n",
    "            # weights is normalized after removing the nan values. \n",
    "            weights = weights/np.sum(weights)\n",
    "\n",
    "            imputed[i,j] = np.dot(fill_by.reshape(-1, 1).T,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(imputed[mask_nans],bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75775, 74296, 74298, ..., 89731, 88788, 79027])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DON'T FORGET TO TURN IT BACK TO THE ORDER!!\n",
    "order\n",
    "# maybe add order as index to imputed and then sort. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(20,12))\n",
    "# corrMatrix = r_PM25.corr()\n",
    "# corrMatrix\n",
    "# sns.heatmap(corrMatrix, annot=True)\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) ARIMA/LSTM/Prophet/the simplest ever for 1-? missing time-steps (short intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA might be problematic since I need to tune the parameters all the time. Does LSTM \n",
    "# require less parameters? in addition, I could predic short intervals but then continue \n",
    "# to predict with the LSTM with the long intervals as -1, as described in machinelearning\n",
    "# mastery. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) Run models 1-2 again with the short-interval imputed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# others\n",
    "# https://impyute.readthedocs.io/en/latest/index.html\n",
    "# https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779\n",
    "# statsmodels MICE\n",
    "# datawig \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5) Statistical imputation, just for comparison?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6) visualize results (box-plots + interactive time series+distribution of imputed values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trash\n",
    "\n",
    "s = pd.Series(tuple(map(tuple, not_nan_idx[test_index])))\n",
    "vals = s.apply(lambda xy: r_PM25.iloc[xy[0],xy[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM25=r_PM25\n",
    "k=2\n",
    "withDays=False\n",
    "\n",
    "kf = KFold(n_splits=k, random_state=0, shuffle=True)\n",
    "not_nan_idx = np.argwhere(PM25.notnull().values)\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      1,       3,       4, ..., 1754019, 1754021, 1754024])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([      0,       2,       6, ..., 1754023, 1754025, 1754026])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([      0,       2,       6, ..., 1754023, 1754025, 1754026])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([      1,       3,       4, ..., 1754019, 1754021, 1754024])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(not_nan_idx):\n",
    "        train_index\n",
    "        test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (52606, 39)\n",
      "[IterativeImputer] Change: 6112.810739330168, scaled tolerance: 1.133 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/impute/_iterative.py:670: ConvergenceWarning:\n",
      "\n",
      "[IterativeImputer] Early stopping criterion not reached.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IterativeImputer(estimator=ExtraTreesRegressor(n_estimators=10, random_state=0),\n",
       "                 max_iter=1, verbose=True)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (52606, 39)\n"
     ]
    }
   ],
   "source": [
    "np_PM25 = PM25.values\n",
    "X_missing = PM25.copy()\n",
    "y_missing = PM25.copy()\n",
    "\n",
    "# y_missing \n",
    "y_missing.iloc[:] = np.nan\n",
    "np_y_missing = y_missing.values\n",
    "\n",
    "# asssign values according to test indexes\n",
    "rows, cols = zip(*not_nan_idx[test_index])\n",
    "vals = np_PM25[rows, cols]\n",
    "np_y_missing[rows, cols] = vals\n",
    "# turn back to dataframe\n",
    "y_missing = pd.DataFrame(np_y_missing,columns=PM25.columns)\n",
    "\n",
    "# X_missing\n",
    "# assign nans according to test indexes\n",
    "np_X_missing = X_missing.values\n",
    "np_X_missing[rows, cols] = np.nan\n",
    "\n",
    "# turn back to dataframe\n",
    "X_missing = pd.DataFrame(np_X_missing,columns=PM25.columns)\n",
    "\n",
    "# mask all missing values\n",
    "indicator = MissingIndicator(missing_values=np.nan)\n",
    "mask_missing_values_original = indicator.fit_transform(PM25)\n",
    "mask_missing_values_all = indicator.fit_transform(X_missing)\n",
    "\n",
    "# perform fit \n",
    "imp.fit(X_missing)\n",
    "imputed_df = imp.transform(X_missing) # impute it\n",
    "imputed_df = pd.DataFrame(imputed_df, columns=X_missing.columns) #turn it from IterativeImputer object to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "# y_train = inverse_y_missing.values\n",
    "y_train = vals\n",
    "\n",
    "# y_pred = inverse_imputed_df.mask(~mask).values\n",
    "np_imputed_df = imputed_df.values\n",
    "y_pred = np_imputed_df[rows, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877013,)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(877013,)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign results\n",
    "RMSE = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "MedianAE = median_absolute_error(y_train, y_pred)\n",
    "MeanAE = mean_absolute_error(y_train,y_pred)\n",
    "R2 = r2_score(y_train,y_pred)\n",
    "# results.append([RMSE,MedianAE,MeanAE,R2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign results\n",
    "RMSE = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "MedianAE = median_absolute_error(y_train, y_pred)\n",
    "MeanAE = mean_absolute_error(y_train,y_pred)\n",
    "R2 = r2_score(y_train,y_pred)\n",
    "results.append([RMSE,MedianAE,MeanAE,R2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12.065151202546158,\n",
       "  4.540000000000001,\n",
       "  6.837151125467923,\n",
       "  0.5649296791889007]]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # do I need to sort all rows so I start with imputing the row with the smallest number \n",
    "# # of missing values? I think so. \n",
    "\n",
    "# # for i,row in enumerate(np_r_PM25):  \n",
    "# #     # euclidean\n",
    "# #     distance.cdist(np_r_PM25, row.reshape(-1, 1).T, lambda u, v: np.sqrt(np.nansum((u-v)**2)))\n",
    "# #     print(i)\n",
    "# # each chunk I get, is an array of all distances of row i with all other rows.\n",
    "# # this is why in the first chunk 0 is first, in the second chunk 0 is second...\n",
    "# # Once distances are calculated, we must sort all of the records in the training \n",
    "# # dataset by their distance to the new data (the desired row). \n",
    "# # We can then select the top k to return as the most similar neighbors. \n",
    "\n",
    "\n",
    "# def get_distance(all_data, imputed_row):\n",
    "\n",
    "#     # when I want to compute it to all elements in the row, including nans:\n",
    "#     dist = distance.cdist(all_data, imputed_row.reshape(-1, 1).T, lambda u, v: np.sqrt(np.nansum((u-v)**2)))\n",
    "#     return dist\n",
    "    \n",
    "# # Locate the most similar neighbors of a row. \n",
    "# # all_data = np_r_PM25\n",
    "# # imputed_row = the current row you want to impute. \n",
    "\n",
    "# def get_neighbors(all_data, imputed_row, num_neighbors):\n",
    "#     dist = get_distance(all_data, imputed_row)\n",
    "#     distances = list(zip(np_r_PM25, dist))    \n",
    "#     distances.sort(key=lambda tup: tup[1])\n",
    "#     neighbors = list()\n",
    "#     for i in range(num_neighbors):\n",
    "#         neighbors.append(distances[i][0])\n",
    "#     return neighbors\n",
    "\n",
    "\n",
    "# # # get_all_neighbors weigh all the neighbors. \n",
    "# # # so no need to sort\n",
    "# # def get_all_neighbors(all_data, imputed_row):\n",
    "# #     dist,no_elements = get_distance(all_data, imputed_row)\n",
    "    \n",
    "# #     distances = list(zip(np_r_PM25, dist, no_elements))\n",
    "\n",
    "# #     return neighbors\n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "# #     distance.cdist(np.delete(np_r_PM25, i,axis=0), row.reshape(-1, 1).T, lambda u, v: np.dot(u, v)/(np.linalg.norm(u)*np.linalg.norm(v)))\n",
    "# #     distance.cdist(np.delete(np_r_PM25, i,axis=0), row.reshape(-1, 1).T, 'cosine') #euclidean\n",
    "\n",
    "# # dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from the begining!\n",
    "# def get_distance(row1, row2):   \n",
    "#     cond = np.array((np.isnan(row1)) | (np.isnan(row2)))    \n",
    "#     # divide the dist by the number of elements compared\n",
    "#     dist = distance.cosine(row1[~cond],row2[~cond])/np.sum(~cond) #euclidean/cosine...\n",
    "#     return dist\n",
    "\n",
    "# def get_neighbors(all_data, imputed_row, num_neighbors):\n",
    "#     distances = list()\n",
    "#     weights = list()\n",
    "#     for row in all_data:\n",
    "#         dist = get_distance(imputed_row, row)\n",
    "#         distances.append((row, dist))\n",
    "#     distances.sort(key=lambda tup: tup[1])\n",
    "#     neighbors = list() \n",
    "#     for i in range(num_neighbors):\n",
    "#         neighbors.append(distances[i][0])\n",
    "#         weights.append(distances[i][1])\n",
    "#     return weights[1:], neighbors[1:] # don't return the imputed row itself"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
