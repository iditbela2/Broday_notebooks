{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import ipywidgets as widgets\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.impute import MissingIndicator\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM25 = pd.read_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/PM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = pd.date_range(start='2016-01-01 00:00:00', end='2018-12-31 23:00:00', freq='30Min') #one less because the last is always nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = PM25.shape[0]-times.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the last index as it is always nan\n",
    "PM25 = PM25[:-1]\n",
    "times = times[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.6 # how much non-missing values are in the time-series in order to include the station?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced PM25 \n",
    "r_PM25 = PM25[start_year:] \n",
    "idx = r_PM25.notnull().sum(axis = 0)/r_PM25.shape[0]>threshold\n",
    "r_PM25 = r_PM25.loc[:, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_PM25.reset_index(inplace=True)\n",
    "r_PM25.drop(labels = 'index',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_PM25['datetime'] = pd.to_datetime(times)\n",
    "r_PM25_withDays = r_PM25.copy()\n",
    "r_PM25_withDays['week day'] = pd.to_datetime(times).dayofweek\n",
    "r_PM25_withDays['month'] = pd.to_datetime(times).month\n",
    "r_PM25_withDays['hour'] = pd.to_datetime(times).hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "AFULA               0.029825\n",
       "ANTOKOLSKY          0.061381\n",
       "EHAD_HAAM           0.316922\n",
       "HOLON               0.079402\n",
       "IRONID              0.053264\n",
       "KVISH4              0.399346\n",
       "RAKEVET_HASHALOM    0.116070\n",
       "REMEZ               0.107858\n",
       "RISHON_LEZION       0.046763\n",
       "YEFET_YAFO          0.205661\n",
       "AHUZA_G             0.021461\n",
       "ATZMAUT_B           0.076645\n",
       "KIRYAT_ATA          0.346671\n",
       "KIRYAT_BINYAMIN     0.051667\n",
       "KIRYAT_TIVON        0.043607\n",
       "NAVE_SHANAAN        0.031118\n",
       "NESHER              0.147398\n",
       "EFRATA              0.030130\n",
       "NAVE_ILAN           0.297419\n",
       "ASHDOD_IGUD         0.085903\n",
       "ASHKELON_SOUTH      0.139490\n",
       "BNEI_DAROM          0.351139\n",
       "DALYA               0.151903\n",
       "GEDERA              0.101072\n",
       "GVARAAM             0.096643\n",
       "KIRYAT_MALAHI       0.039596\n",
       "NIR_ISRAEL          0.121317\n",
       "ORT                 0.325039\n",
       "SDEROT              0.061628\n",
       "SDE_YOAV            0.067179\n",
       "YAHALOM             0.366631\n",
       "BEER_SHEVA          0.101167\n",
       "EAST_NEGEV          0.112573\n",
       "KFAR_MASARIK        0.093164\n",
       "PARDES_HANA         0.390032\n",
       "RAANANA             0.162377\n",
       "SHFEYA              0.048968\n",
       "ASHALIM             0.275805\n",
       "NEOT_HAKIKAR        0.103049\n",
       "dtype: float64"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null percentages\n",
    "r_PM25.shape[1]\n",
    "1-r_PM25.notnull().sum(axis = 0)/r_PM25.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52606"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2051634"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_PM25.shape[0]\n",
    "r_PM25.shape[1]\n",
    "r_PM25.shape[1]*r_PM25.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep all random stuff identical\n",
    "rnd_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of all non-nan indexes, perform 10-fold cross validation.\n",
    "# the test is y_missing. copy r_PM25, put all null inside, and assign values from r_PM25 according to test indexes. \n",
    "# the train is X_missing. copy r_PM25, and assign nans according to test indexes. \n",
    "# the splitting currently doesn't try to preserve the original relative missing intervals\n",
    "# of each feature. maybe I will add it somehow later. \n",
    "\n",
    "def KFold_cross_validation(imp,PM25,k,withDays=False):\n",
    "    kf = KFold(n_splits=k, random_state=rnd_state, shuffle=True)\n",
    "    not_nan_idx = np.argwhere(PM25.notnull().values)\n",
    "    results = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(not_nan_idx):\n",
    "        np_PM25 = PM25.values\n",
    "        X_missing = PM25.copy()\n",
    "        y_missing = PM25.copy()\n",
    "        \n",
    "        # y_missing \n",
    "        y_missing.iloc[:] = np.nan\n",
    "        np_y_missing = y_missing.values\n",
    "        \n",
    "        # asssign values according to test indexes\n",
    "        rows, cols = zip(*not_nan_idx[test_index])\n",
    "        vals = np_PM25[rows, cols]\n",
    "        np_y_missing[rows, cols] = vals\n",
    "        # turn back to dataframe\n",
    "        y_missing = pd.DataFrame(np_y_missing,columns=PM25.columns)\n",
    "\n",
    "        # X_missing\n",
    "        # assign nans according to test indexes\n",
    "        np_X_missing = X_missing.values\n",
    "        np_X_missing[rows, cols] = np.nan\n",
    "        \n",
    "        # turn back to dataframe\n",
    "        X_missing = pd.DataFrame(np_X_missing,columns=PM25.columns)\n",
    "        \n",
    "        if withDays:\n",
    "            X_missing['week day']=PM25['week day']\n",
    "            X_missing['hour']=PM25['hour']\n",
    "            X_missing['month']=PM25['month']\n",
    "        \n",
    "        # mask all missing values\n",
    "        indicator = MissingIndicator(missing_values=np.nan)\n",
    "        mask_missing_values_original = indicator.fit_transform(PM25)\n",
    "        mask_missing_values_all = indicator.fit_transform(X_missing)\n",
    "\n",
    "        # perform fit \n",
    "        imp.fit(X_missing)\n",
    "        imputed_df = imp.transform(X_missing) # impute it\n",
    "        imputed_df = pd.DataFrame(imputed_df, columns=X_missing.columns) #turn it from IterativeImputer object to a dataframe\n",
    "        \n",
    "        if withDays:\n",
    "            imputed_df.drop(['week day','hour','month'],axis = 1, inplace=True)\n",
    "                       \n",
    "        # evaluate\n",
    "        y_train = vals\n",
    "        np_imputed_df = imputed_df.values\n",
    "        y_pred = np_imputed_df[rows, cols]\n",
    "        \n",
    "        # assign results\n",
    "        RMSE = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "        MedianAE = median_absolute_error(y_train, y_pred)\n",
    "        MeanAE = mean_absolute_error(y_train,y_pred)\n",
    "        R2 = r2_score(y_train,y_pred)\n",
    "        results.append([RMSE,MedianAE,MeanAE,R2])\n",
    "               \n",
    "    results = pd.DataFrame(results, columns=['RMSE','MedianAE','MeanAE','R2'])\n",
    "    \n",
    "    return results\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (1) IterativeImputer with BayesianRidge and ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_RF = IterativeImputer(max_iter=5,estimator=ExtraTreesRegressor(n_estimators=10,random_state=rnd_state),verbose=True) \n",
    "imp_BR = IterativeImputer(max_iter=10,estimator=BayesianRidge(),verbose=True) \n",
    "# try also to change the initial imputer - mean/median/constant...\n",
    "# and n_estimators (number of trees in the forest...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A - without days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (52606, 39)\n",
      "[IterativeImputer] Change: 6296.2617190883475, scaled tolerance: 1.2255 \n",
      "[IterativeImputer] Completing matrix with shape (52606, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/impute/_iterative.py:670: ConvergenceWarning:\n",
      "\n",
      "[IterativeImputer] Early stopping criterion not reached.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(877014,)\n",
      "(877014,)\n",
      "[IterativeImputer] Completing matrix with shape (52606, 39)\n",
      "[IterativeImputer] Change: 6112.810739330168, scaled tolerance: 1.133 \n",
      "[IterativeImputer] Completing matrix with shape (52606, 39)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/impute/_iterative.py:670: ConvergenceWarning:\n",
      "\n",
      "[IterativeImputer] Early stopping criterion not reached.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(877013,)\n",
      "(877013,)\n"
     ]
    }
   ],
   "source": [
    "results_woD_RF = KFold_cross_validation(imp_RF,r_PM25,k=10,withDays=False)\n",
    "results_woD_BR = KFold_cross_validation(imp_BR,r_PM25,k=10,withDays=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MedianAE</th>\n",
       "      <th>MeanAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.112761</td>\n",
       "      <td>4.55</td>\n",
       "      <td>6.847774</td>\n",
       "      <td>0.564379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.065151</td>\n",
       "      <td>4.54</td>\n",
       "      <td>6.837151</td>\n",
       "      <td>0.564930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        RMSE  MedianAE    MeanAE        R2\n",
       "0  12.112761      4.55  6.847774  0.564379\n",
       "1  12.065151      4.54  6.837151  0.564930"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_woD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B - without days, with normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C - with days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_PM25_withDays = r_PM25.copy()\n",
    "r_PM25_withDays['week day'] = pd.to_datetime(times).dayofweek\n",
    "r_PM25_withDays['month'] = pd.to_datetime(times).month\n",
    "r_PM25_withDays['hour'] = pd.to_datetime(times).hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_wD_RF = KFold_cross_validation(imp_RF,r_PM25_withDays,k=10,withDays=True)\n",
    "results_wD_BR = KFold_cross_validation(imp_BR,r_PM25_withDays,k=10,withDays=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D - with days, with normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind/other met./other pollutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A - iterative imputer - VERY SLOW!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(max_iter=1,estimator=KNeighborsRegressor(n_neighbors=20,weights='distance',n_jobs=-1),verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = KFold_cross_validation(imp,r_PM25,k=2,withDays=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B - my KNN implemintation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np_r_PM25 = r_PM25.iloc[:10,:].dropna(how='all',axis=1).values\n",
    "# np_r_PM25 = r_PM25.iloc[:10,:].values\n",
    "np_r_PM25 = r_PM25.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do I need to sort all rows so I start with imputing the row with the smallest number \n",
    "# of missing values? not sure it matters.\n",
    "\n",
    "# for i,row in enumerate(np_r_PM25):  \n",
    "#     # euclidean\n",
    "#     distance.cdist(np_r_PM25, row.reshape(-1, 1).T, lambda u, v: np.sqrt(np.nansum((u-v)**2)))\n",
    "#     print(i)\n",
    "# each chunk I get, is an array of all distances of row i with all other rows.\n",
    "# this is why in the first chunk 0 is first, in the second chunk 0 is second...\n",
    "# Once distances are calculated, we must sort all of the records in the training \n",
    "# dataset by their distance to the new data (the desired row). \n",
    "# We can then select the top k to return as the most similar neighbors. \n",
    "    \n",
    "def euclidean_distance(all_data, imputed_row):\n",
    "    dist = distance.cdist(all_data, imputed_row.reshape(-1, 1).T, lambda u, v: np.sqrt(np.nansum((u-v)**2)))\n",
    "    return dist\n",
    "    \n",
    "# Locate the most similar neighbors of a row. \n",
    "# all_data = np_r_PM25\n",
    "# imputed_row = the current row you want to impute. \n",
    "\n",
    "def get_neighbors(all_data, imputed_row, num_neighbors):\n",
    "    dist = euclidean_distance(all_data, imputed_row)\n",
    "    distances = list(zip(np_r_PM25, dist))    \n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors\n",
    "\n",
    "# get_all_neighbors weigh all the neighbors. \n",
    "# so no need to sort\n",
    "def get_all_neighbors(all_data, imputed_row):\n",
    "    dist = euclidean_distance(all_data, imputed_row)\n",
    "    distances = list(zip(np_r_PM25, dist))\n",
    "\n",
    "    return neighbors\n",
    "    \n",
    "        \n",
    "#     cosine doesnt work\n",
    "#     distance.cdist(np.delete(np_r_PM25, i,axis=0), row.reshape(-1, 1).T, lambda u, v: np.dot(u, v)/(np.linalg.norm(u)*np.linalg.norm(v)))\n",
    "#     distance.cdist(np.delete(np_r_PM25, i,axis=0), row.reshape(-1, 1).T, 'cosine') #euclidean\n",
    "\n",
    "# dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.39201167])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7  4.8  nan  8.9  6.3  6.6  nan 11.  14.7  nan  1.7 10.5  1.4  0.2\n",
      "  3.8  0.5  1.7  2.9  6.   nan  6.8  nan  nan  3.8  5.9  0.9  5.5  nan\n",
      "  1.5  2.9 25.2  4.6 15.6 10.3  nan  3.7  nan  nan  nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan]\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan]\n",
      "[ 4.3  6.8  nan  8.1  nan  nan  nan  nan  nan  nan  4.6  nan  4.5  0.1\n",
      "  4.7  0.3  2.1  3.5  4.   2.8  nan  nan  nan  1.1  5.7  0.1  3.2  nan\n",
      "  nan 11.3 22.5  1.   9.   6.8  nan  1.2  nan  nan  nan]\n",
      "[ 2.7  2.5 10.7  nan  4.1  nan  2.5  7.7  nan 10.2  3.6  4.8  2.8  2.3\n",
      "  2.8  5.   nan  5.6  nan 13.2  1.1  5.1  6.7  nan  nan  3.5  2.8  nan\n",
      "  2.4  0.9  nan  nan 22.3  4.2 10.   nan  5.  11.   5.8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.7,  4.8,  nan,  8.9,  6.3,  6.6,  nan, 11. , 14.7,  nan,  1.7,\n",
       "       10.5,  1.4,  0.2,  3.8,  0.5,  1.7,  2.9,  6. ,  nan,  6.8,  nan,\n",
       "        nan,  3.8,  5.9,  0.9,  5.5,  nan,  1.5,  2.9, 25.2,  4.6, 15.6,\n",
       "       10.3,  nan,  3.7,  nan,  nan,  nan])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors = get_neighbors(np_r_PM25, np_r_PM25[0,:], 5)\n",
    "for neighbor in neighbors:\n",
    "    print(neighbor)   \n",
    "    \n",
    "np_r_PM25[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (3) ARIMA/LSTM/Prophet for 1-? missing time-steps (short intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (4) The simplest interpolation for 1-? missing time-steps (short intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA might be problematic since I need to tune the parameters all the time. Does LSTM \n",
    "# require less parameters? in addition, I could predic short intervals but then continue \n",
    "# to predict with the LSTM with the long intervals as -1, as described in machinelearning\n",
    "# mastery. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (5) Runing models 1-2 again with the short-interval imputed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# others\n",
    "# https://impyute.readthedocs.io/en/latest/index.html\n",
    "# https://towardsdatascience.com/6-different-ways-to-compensate-for-missing-values-data-imputation-with-examples-6022d9ca0779\n",
    "# statsmodels MICE\n",
    "# datawig \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (6) Statistical imputation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trash\n",
    "\n",
    "s = pd.Series(tuple(map(tuple, not_nan_idx[test_index])))\n",
    "vals = s.apply(lambda xy: r_PM25.iloc[xy[0],xy[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM25=r_PM25\n",
    "k=2\n",
    "withDays=False\n",
    "\n",
    "kf = KFold(n_splits=k, random_state=0, shuffle=True)\n",
    "not_nan_idx = np.argwhere(PM25.notnull().values)\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([      1,       3,       4, ..., 1754019, 1754021, 1754024])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([      0,       2,       6, ..., 1754023, 1754025, 1754026])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([      0,       2,       6, ..., 1754023, 1754025, 1754026])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([      1,       3,       4, ..., 1754019, 1754021, 1754024])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(not_nan_idx):\n",
    "        train_index\n",
    "        test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (52606, 39)\n",
      "[IterativeImputer] Change: 6112.810739330168, scaled tolerance: 1.133 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/impute/_iterative.py:670: ConvergenceWarning:\n",
      "\n",
      "[IterativeImputer] Early stopping criterion not reached.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IterativeImputer(estimator=ExtraTreesRegressor(n_estimators=10, random_state=0),\n",
       "                 max_iter=1, verbose=True)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (52606, 39)\n"
     ]
    }
   ],
   "source": [
    "np_PM25 = PM25.values\n",
    "X_missing = PM25.copy()\n",
    "y_missing = PM25.copy()\n",
    "\n",
    "# y_missing \n",
    "y_missing.iloc[:] = np.nan\n",
    "np_y_missing = y_missing.values\n",
    "\n",
    "# asssign values according to test indexes\n",
    "rows, cols = zip(*not_nan_idx[test_index])\n",
    "vals = np_PM25[rows, cols]\n",
    "np_y_missing[rows, cols] = vals\n",
    "# turn back to dataframe\n",
    "y_missing = pd.DataFrame(np_y_missing,columns=PM25.columns)\n",
    "\n",
    "# X_missing\n",
    "# assign nans according to test indexes\n",
    "np_X_missing = X_missing.values\n",
    "np_X_missing[rows, cols] = np.nan\n",
    "\n",
    "# turn back to dataframe\n",
    "X_missing = pd.DataFrame(np_X_missing,columns=PM25.columns)\n",
    "\n",
    "# mask all missing values\n",
    "indicator = MissingIndicator(missing_values=np.nan)\n",
    "mask_missing_values_original = indicator.fit_transform(PM25)\n",
    "mask_missing_values_all = indicator.fit_transform(X_missing)\n",
    "\n",
    "# perform fit \n",
    "imp.fit(X_missing)\n",
    "imputed_df = imp.transform(X_missing) # impute it\n",
    "imputed_df = pd.DataFrame(imputed_df, columns=X_missing.columns) #turn it from IterativeImputer object to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "# y_train = inverse_y_missing.values\n",
    "y_train = vals\n",
    "\n",
    "# y_pred = inverse_imputed_df.mask(~mask).values\n",
    "np_imputed_df = imputed_df.values\n",
    "y_pred = np_imputed_df[rows, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877013,)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(877013,)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign results\n",
    "RMSE = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "MedianAE = median_absolute_error(y_train, y_pred)\n",
    "MeanAE = mean_absolute_error(y_train,y_pred)\n",
    "R2 = r2_score(y_train,y_pred)\n",
    "# results.append([RMSE,MedianAE,MeanAE,R2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign results\n",
    "RMSE = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "MedianAE = median_absolute_error(y_train, y_pred)\n",
    "MeanAE = mean_absolute_error(y_train,y_pred)\n",
    "R2 = r2_score(y_train,y_pred)\n",
    "results.append([RMSE,MedianAE,MeanAE,R2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[12.065151202546158,\n",
       "  4.540000000000001,\n",
       "  6.837151125467923,\n",
       "  0.5649296791889007]]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
