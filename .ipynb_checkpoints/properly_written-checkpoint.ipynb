{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import ipywidgets as widgets\n",
    "from tqdm.auto import tqdm \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.impute import MissingIndicator\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_absolute_error #=mean error (Simon 2012)\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import nan_euclidean_distances\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import rcParams, cycler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(threshold, start_time):\n",
    "    PM25 = pd.read_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/PM25\")\n",
    "\n",
    "    times = pd.date_range(start=start_time, end='2018-12-31 23:00:00', freq='30Min') #one less because the last is always nan\n",
    "\n",
    "    start_idx = PM25.shape[0]-times.shape[0]\n",
    "\n",
    "    # remove the last index as it is always nan\n",
    "    PM25 = PM25[:-1]\n",
    "    times = times[:-1]\n",
    "\n",
    "    # reduced PM25 \n",
    "    r_PM25 = PM25[start_idx:] \n",
    "    idx = r_PM25.notnull().sum(axis = 0)/r_PM25.shape[0]>threshold\n",
    "    r_PM25 = r_PM25.loc[:, idx]\n",
    "\n",
    "    r_PM25.reset_index(inplace=True)\n",
    "    r_PM25.drop(labels = 'index',axis=1, inplace=True)\n",
    "    \n",
    "    return times, r_PM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a np_array np_y_missing, fill the np_y_missing with values where the validation\n",
    "# indexes are chosen. \n",
    "\n",
    "def get_validation_index(PM25, interval_length, s, exclude):\n",
    "    \n",
    "    np.random.seed(0) # if want to reproduce. \n",
    "    # I think I should do it many times for each length\n",
    "    \n",
    "    idx_start = np.random.choice([i for i in range(0,len(PM25.iloc[:,s])) if i not in exclude])\n",
    "    condition = PM25.iloc[idx_start:idx_start+interval_length,s].isnull().rolling(interval_length,min_periods=0).sum().max()\n",
    "\n",
    "    # I allow some nan values (0.5%) to be inside in validation interval. \n",
    "    while ((condition>interval_length/100/2) or (np.isnan(PM25.iloc[idx_start-1,s])) or (np.isnan(PM25.iloc[idx_start+interval_length+1,s])) or ((idx_start+interval_length+1)>len(PM25.iloc[:,s]))):\n",
    "        idx_start = np.random.choice([i for i in range(0,len(PM25.iloc[:,s])) if i not in exclude])\n",
    "        condition = PM25.iloc[idx_start:idx_start+interval_length,s].isnull().rolling(interval_length,min_periods=0).sum().max()\n",
    "\n",
    "    return (idx_start,idx_start + interval_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that returns X_missing, y_missing (splits the data according to Interval Length(IL))\n",
    "def return_X_y(PM25,IL):\n",
    " \n",
    "    X_missing = PM25.copy()\n",
    "    y_missing = PM25.copy() \n",
    "\n",
    "    np_r_PM25_y_mask = PM25.copy().values\n",
    "    np_r_PM25_y_mask[:] = 0\n",
    "    \n",
    "    for s in tqdm(range(np_r_PM25_y_mask.shape[1])):\n",
    "        \n",
    "        total_exclude = [] # a list of excluded indexes (to not overlap the chunks. not \n",
    "        # sure it is important if I evaluate seperately for each chunk size).\n",
    "\n",
    "        interval_length = IL*2\n",
    "        for i in range(int(720/IL)):\n",
    "            (a,b) = get_validation_index(PM25, interval_length, s, total_exclude)\n",
    "            total_exclude.append(range(a,b))\n",
    "            np_r_PM25_y_mask[a:b,s] = -1\n",
    "                      \n",
    "    # y_missing \n",
    "    y_missing.iloc[:] = np.nan\n",
    "    np_y_missing = y_missing.values\n",
    "    np_X_missing = X_missing.values\n",
    "\n",
    "    # put in np_y_missing \n",
    "    np_y_missing[np_r_PM25_y_mask==-1]=np_X_missing[np_r_PM25_y_mask==-1]\n",
    "    # X_missing\n",
    "    np_X_missing[np_r_PM25_y_mask==-1]=np.nan\n",
    "\n",
    "    # turn back to dataframe\n",
    "#     X_missing = pd.DataFrame(np_X_missing,columns=PM25.columns)\n",
    "\n",
    "    \n",
    "    return np_X_missing, np_y_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that imputes for each of the methods\n",
    "\n",
    "def impute_ii_BR(np_X_missing, num_iter):\n",
    "    imp = IterativeImputer(max_iter=num_iter,estimator=BayesianRidge(),verbose=True) \n",
    "    imp.fit(X_missing)\n",
    "    imputed = imp.transform(X_missing) \n",
    "    return imputed\n",
    "\n",
    "def impute_ii_RF(np_X_missing, num_iter, num_trees, rnd_state_forRF):\n",
    "#     n_jobs=-1 # add to ExtraTreesRegressor if I want all cores. \n",
    "    imp = IterativeImputer(max_iter=num_iter,estimator=ExtraTreesRegressor(n_estimators=num_trees,random_state=rnd_state_forRF),verbose=True) \n",
    "    imp.fit(X_missing)\n",
    "    imputed = imp.transform(X_missing)  \n",
    "    return imputed\n",
    "\n",
    "def impute_ii_KNN(np_X_missing, num_iter, num_neighbors, weight_type): #'uniform','distance'\n",
    "#     n_jobs=-1 # add to KNeighborsRegressor if I want all cores. \n",
    "    imp = IterativeImputer(max_iter=num_iter,estimator=KNeighborsRegressor(n_neighbors=num_neighbors,weights=weight_type),verbose=True) \n",
    "    imp.fit(X_missing)\n",
    "    imputed = imp.transform(X_missing)     \n",
    "    return imputed\n",
    "\n",
    "def impute_my_KNN(np_X_missing, k):\n",
    "\n",
    "    imputed = np_X_missing.copy() \n",
    "    all_data_mask_nans = imputed.copy()\n",
    "    mask_nans = np.isnan(imputed)\n",
    "    all_data_mask_nans[mask_nans]=0\n",
    "\n",
    "    batch_size = 300\n",
    "    not_nan_mask = 1-np.isnan(np_X_missing).astype(int)\n",
    "    # all_data_norm = all_data_mask_nans / np.linalg.norm(all_data_mask_nans,axis=1)[:,np.newaxis] # normalize BY norm\n",
    "    all_data_norm = np_X_missing / np.nanstd(np_X_missing, axis=0) # normalize BY norm \n",
    "\n",
    "\n",
    "    np_corrMatrix = pd.DataFrame(imputed).corr().values\n",
    "    \n",
    "    for cind in tqdm(range(np_X_missing.shape[1])): #tqdm(range(np_X_missing.shape[1]-33)) #range(34,int(np_X_missing.shape[1]/3)+1) #+1=AFULA, +34=all \n",
    "        nan_column_mask = np.isnan(np_X_missing[:,cind])\n",
    "        not_nan_column_mask = np.logical_not(nan_column_mask)\n",
    "\n",
    "        not_nan_in_colom_all_data_norm = all_data_norm[not_nan_column_mask, :]*np_corrMatrix[:,cind]\n",
    "\n",
    "        not_nan_not_nan_mask = not_nan_mask[not_nan_column_mask, :] #relevant rows for this column (not nan)\n",
    "\n",
    "        not_nan_column = np_X_missing[not_nan_column_mask,cind]    \n",
    "        nan_ind = np.argwhere(nan_column_mask)\n",
    "        \n",
    "        for i in tqdm(range(0, len(nan_ind), batch_size), leave=False):\n",
    "            rinds = np.ravel(nan_ind[i:i+batch_size])\n",
    "            batch = all_data_norm[rinds, :]*np_corrMatrix[:,cind]\n",
    "\n",
    "            batch_non_nan_mask = not_nan_mask[rinds, :]\n",
    "            counts = np.dot(not_nan_not_nan_mask, batch_non_nan_mask.T)\n",
    "\n",
    "            dists = nan_euclidean_distances(not_nan_in_colom_all_data_norm, batch)\n",
    "\n",
    "            weights = counts/dists\n",
    "            min_thr = np.partition(weights,-(k+1),axis=0)[-(k+1),:]\n",
    "            weights = weights-min_thr\n",
    "            # !If all the coordinates are missing or if there are no common present coordinates then NaN is returned in dists for that pair!\n",
    "            weights[(weights<0) | (np.isnan(weights))] = 0\n",
    "            weights = weights / weights.sum(axis=0)\n",
    "\n",
    "            values = np.dot(weights.T, not_nan_column)\n",
    "            imputed[rinds, cind] = values\n",
    "            \n",
    "    return imputed\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that cumputes validation results\n",
    "\n",
    "def validate(imputed, np_y_missing):\n",
    "    \n",
    "    y_train = np_y_missing[~np.isnan(np_y_missing)]\n",
    "    y_pred = imputed[~np.isnan(np_y_missing)]\n",
    "    \n",
    "    # assign results\n",
    "    RMSE = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "    MedianAE = median_absolute_error(y_train, y_pred)\n",
    "    MeanAE = mean_absolute_error(y_train,y_pred)\n",
    "    R2 = r2_score(y_train,y_pred)\n",
    "    \n",
    "    results = [RMSE,MedianAE,MeanAE,R2]\n",
    "    results = pd.DataFrame(np.array(results).reshape(-1,1).T, columns=['RMSE','MedianAE','MeanAE','R2'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that displays the distribution of the imputed Vs. original data\n",
    "\n",
    "# def \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function for box plots\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.6 # how much non-missing values are in the time-series in order to include the station?\n",
    "start_time = '2013-01-01 00:00:00'\n",
    "times, r_PM25 = initialize(threshold, start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a747d460ae4d05b7d760f78afe960e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=34), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "IL = [720,120,24,12,2,1,0.5]   \n",
    "# IL = [1200, 100, 50, 10, 5, 1, 0.5]\n",
    "np_X_missing, np_y_missing = return_X_y(r_PM25,IL[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the size of the missing values is as desired\n",
    "# np.argwhere(~np.isnan(y_missing.iloc[:,1]))[-1]-np.argwhere(~np.isnan(y_missing.iloc[:,1]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IterativeImputer Baysian Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (105166, 34)\n",
      "[IterativeImputer] Change: 3711.0960102026675, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 848.9010221425344, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 357.3802468574471, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 182.27584715128992, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Change: 116.87739314451392, scaled tolerance: 1.6975 \n",
      "[IterativeImputer] Completing matrix with shape (105166, 34)\n"
     ]
    }
   ],
   "source": [
    "# PLEASE NORMALIZE BEFORE\n",
    "\n",
    "# impute\n",
    "num_iter = 5\n",
    "imputed = impute_ii_BR(np_X_missing, num_iter)\n",
    "# validate\n",
    "results = validate(imputed, np_y_missing)\n",
    "\n",
    "# save \n",
    "imputed_df = pd.DataFrame(imputed, columns=r_PM25.columns) #turn it from IterativeImputer object to a dataframe\n",
    "imputed_df.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/imputed_ii_BR_\"+str(IL[0])+'_'+str(num_iter))\n",
    "results.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/results_ii_BR_\"+str(IL[0])+'_'+str(num_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IterativeImputer Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute\n",
    "num_iter = 5\n",
    "num_trees = 10\n",
    "rnd_state_forRF = 0\n",
    "\n",
    "imputed = impute_ii_RF(np_X_missing, num_iter, num_trees, rnd_state_forRF)\n",
    "    \n",
    "# validate\n",
    "results = validate(imputed, np_y_missing)\n",
    "\n",
    "# save \n",
    "imputed_df = pd.DataFrame(imputed, columns=r_PM25.columns) #turn it from IterativeImputer object to a dataframe\n",
    "imputed_df.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/imputed_ii_RF_\"+str(IL[0])+'_'+str(num_iter))\n",
    "results.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/results_ii_RF_\"+str(IL[0])+'_'+str(num_iter)+'_'+str(num_trees))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IterativeImputer KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_type = 'distance' #'uniform','distance'\n",
    "num_iter = 5\n",
    "num_neighbors = 10\n",
    "\n",
    "imputed = impute_ii_KNN(np_X_missing, num_iter, num_neighbors, weight_type)\n",
    "\n",
    "# validate\n",
    "results = validate(imputed, np_y_missing)\n",
    "\n",
    "# save \n",
    "imputed_df = pd.DataFrame(imputed, columns=r_PM25.columns) #turn it from IterativeImputer object to a dataframe\n",
    "imputed_df.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/imputed_ii_KNN_\"+str(IL[0])+'_'+str(num_iter))\n",
    "results.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/results_ii_KNN_\"+str(IL[0])+'_'+str(num_iter)+'_'+str(num_neighbors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894609032f674ade83c09a72b9724124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=34), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ced6d0f9cf5420998155926134056b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=34), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-6b156213acf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimputed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimpute_my_KNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_X_missing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_y_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-130-aa76c0aff7cc>\u001b[0m in \u001b[0;36mimpute_my_KNN\u001b[0;34m(np_X_missing, num_neighbors)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mmin_thr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmin_thr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# !If all the coordinates are missing or if there are no common present coordinates then NaN is returned in dists for that pair!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "num_neighbors = 9\n",
    "imputed = impute_my_KNN(np_X_missing, num_neighbors)\n",
    "\n",
    "# validate\n",
    "results = validate(imputed, np_y_missing)\n",
    "\n",
    "# save \n",
    "imputed_df = pd.DataFrame(imputed, columns=r_PM25.columns) #turn it from IterativeImputer object to a dataframe\n",
    "imputed_df.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/imputed_my_KNN_\"+str(IL[0])+'_'+str(num_iter))\n",
    "results.to_pickle(\"/Users/iditbela/Documents/Broday/saved_data_from_notebooks/results_my_KNN_\"+str(IL[0])+'_'+str(num_iter)+'_'+str(num_neighbors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m (number of iterations) should be approximately as the average missing percentage. \n",
    "# which is about 15% in my case. ok to start with 5-10 though. \n",
    "# loose the 5 rows where all rows are empty!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ways to check randomness - https://www.theanalysisfactor.com/missing-data-mechanism/\n",
    "# mark missing values in 1 and non-missing in zero. run a t-test or chi-square test \n",
    "# between one variable(column) and all other variables(columns). I think it should\n",
    "# tell me if they are drown from the same poplutation (I want p-value not significant,\n",
    "# meaning they are from different populations). if they come from the same population \n",
    "# I suspect that it is not random.\n",
    "# MAYBE THE 0-1 IS TO TEST THE ORDER OF THE VALUES? IF IN RANDOM. = TEST FOR MCAR\n",
    "# another option (I think test for MAR) is if I suspect that it is not completely random \n",
    "# (due to malfunctioning in a certain\n",
    "# time maybe), I can try to train a logistic regression to see if time of day can \n",
    "# predict the missing non-missing classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribution of the imputed values Vs. the dist. of the non-missing values.\n",
    "\n",
    "\n",
    "'''The idea is that good imputations have a distribution \n",
    "similar to the observed data. In other words, the imputations\n",
    "could have been real values had they been observed. \n",
    "Except under MCAR, the distributions do not need to be identical, \n",
    "since strong MAR mechanisms may induce systematic differences between \n",
    "the two distributions. However, any dramatic differences between the \n",
    "imputed and observed data should certainly alert us to the possibility\n",
    "that something is wrong.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stefvanbuuren.name/fimd/sec-nutshell.html\n",
    "# http://www.stat.columbia.edu/~gelman/arm/missing.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
